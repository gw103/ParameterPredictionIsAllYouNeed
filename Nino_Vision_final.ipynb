{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmPjHavV18_I",
        "outputId": "88c1ccce-d11d-4534-a368-925005b61abb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SamsungSAILMontreal/nino.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XldB94GS2Dk3",
        "outputId": "12d6037f-1e39-430a-afc6-29297b7b8bb7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nino'...\n",
            "remote: Enumerating objects: 190, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 190 (delta 14), reused 12 (delta 12), pack-reused 171 (from 1)\u001b[K\n",
            "Receiving objects: 100% (190/190), 59.78 MiB | 37.86 MiB/s, done.\n",
            "Resolving deltas: 100% (91/91), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd nino\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1eGkB2w2_zc",
        "outputId": "2b0ac9bb-eab4-4761-e0dd-bb5955b9e073"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nino\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_fdSTPW4GJc",
        "outputId": "7f4433aa-6046-41fb-a74c-d506b4bbb02a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoints  graph    nino_step.py  README.md  train\t    train_vision.py\n",
            "figs\t     LICENSE  optim\t    results    train_lm.py  utils\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I59gH4654P76",
        "outputId": "f34ba929-6b9f-480f-ea28-9eba648ec2cf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.9)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install performer_pytorch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3CfR8jCt9xp",
        "outputId": "49a8710a-34de-4d8e-94cd-fd02869f3b01"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting performer_pytorch\n",
            "  Downloading performer_pytorch-1.1.4-py3-none-any.whl.metadata (763 bytes)\n",
            "Requirement already satisfied: einops>=0.3 in /usr/local/lib/python3.10/dist-packages (from performer_pytorch) (0.8.0)\n",
            "Collecting local-attention>=1.1.1 (from performer_pytorch)\n",
            "  Downloading local_attention-1.9.15-py3-none-any.whl.metadata (683 bytes)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from performer_pytorch) (2.5.1+cu121)\n",
            "Collecting axial-positional-embedding>=0.1.0 (from performer_pytorch)\n",
            "  Downloading axial_positional_embedding-0.2.1.tar.gz (2.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->performer_pytorch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->performer_pytorch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->performer_pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->performer_pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->performer_pytorch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->performer_pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.6->performer_pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->performer_pytorch) (3.0.2)\n",
            "Downloading performer_pytorch-1.1.4-py3-none-any.whl (13 kB)\n",
            "Downloading local_attention-1.9.15-py3-none-any.whl (9.0 kB)\n",
            "Building wheels for collected packages: axial-positional-embedding\n",
            "  Building wheel for axial-positional-embedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for axial-positional-embedding: filename=axial_positional_embedding-0.2.1-py3-none-any.whl size=2887 sha256=6e35c40eade1e459214f933f2ee8f523ffc692c42c0b7082d8239dd9e6cb48e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/cb/39/7ce7ff2d2fd37cfe1fe7b3a3c43cf410632b2ad3b3f3986d73\n",
            "Successfully built axial-positional-embedding\n",
            "Installing collected packages: local-attention, axial-positional-embedding, performer_pytorch\n",
            "Successfully installed axial-positional-embedding-0.2.1 local-attention-1.9.15 performer_pytorch-1.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train_vision.py --task C10-32 --nino_ckpt_hybrid \"../nino_gru_head_ctx10_hor40.pt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYmOYNzO2PGd",
        "outputId": "e6442f96-20f8-4527-e968-1e54779cb62f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Environment:\n",
            "git commit          : 1ae2c09\n",
            "hostname            : 10d1e8aed3f2\n",
            "torch               : 2.5.1+cu121\n",
            "torchvision         : 0.20.1+cu121\n",
            "transformers        : 4.46.3\n",
            "cuda available      : True\n",
            "cudnn enabled       : True\n",
            "cuda version        : 12.1\n",
            "start time          : 20241209-171749\n",
            "\n",
            "Script Arguments:\n",
            "batch_size          : 128\n",
            "checkpointing_steps : None\n",
            "device              : cuda\n",
            "env                 : {'git commit': '1ae2c09', 'hostname': '10d1e8aed3f2', 'torch': '2.5.1+cu121', 'torchvision': '0.20.1+cu121', 'transformers': '4.46.3', 'cuda available': True, 'cudnn enabled': True, 'cuda version': '12.1', 'start time': '20241209-171749'}\n",
            "head                : None\n",
            "log_interval        : 100\n",
            "lr                  : None\n",
            "max_train_steps     : 10000\n",
            "nino_ckpt_gru       : ../nino_gru_head_ctx10_hor40.pt\n",
            "nino_ckpt_hybrid    : ../nino_gru_head_ctx10_hor40.pt\n",
            "nino_ckpt_lstm      : ../nino_lstm_ctx10_head_ctx10_hor40.pt\n",
            "nino_ckpt_mlp       : ../nino_mlp_head_ctx10_hor40.pt\n",
            "num_workers         : 4\n",
            "output_dir          : ..\results\n",
            "period              : 1000\n",
            "resume_from_checkpoi: None\n",
            "seed                : 1000\n",
            "task                : C10-32\n",
            "verbose             : 1\n",
            "wd                  : 0\n",
            "\n",
            "\n",
            "task {'net_args': {'hid': (32, 64, 64), 'in_channels': 3, 'num_classes': 10}, 'dataset': 'CIFAR10', 'norm': ((0.49139968, 0.48215827, 0.44653124), (0.24703233, 0.24348505, 0.26158768)), 'lr': 0.003, 'target': 72.5}\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Net(\n",
            "  (fc): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "    (5): ReLU()\n",
            "    (6): AdaptiveAvgPool2d(output_size=1)\n",
            "    (7): Flatten(start_dim=1, end_dim=-1)\n",
            "    (8): Linear(in_features=64, out_features=10, bias=True)\n",
            "  )\n",
            ") params 56970 total param norm 7.6108598709106445\n",
            "base optimizer AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.003\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "\n",
            "Training C10-32 with 359 batches per epoch for 28 epochs\n",
            "Train 0100/10000: \tTrain loss: 1.8269 \tVal loss: 1.7810 \tVal acc: 31.76% \t(sec/b=0.023, cuda=3.391G)\n",
            "Train 0200/10000: \tTrain loss: 1.7200 \tVal loss: 1.6796 \tVal acc: 37.36% \t(sec/b=0.020, cuda=3.391G)\n",
            "Train 0300/10000: \tTrain loss: 1.6287 \tVal loss: 1.6228 \tVal acc: 40.80% \t(sec/b=0.019, cuda=3.391G)\n",
            "Train 0400/10000: \tTrain loss: 1.4526 \tVal loss: 1.5304 \tVal acc: 44.01% \t(sec/b=0.019, cuda=3.393G)\n",
            "Train 0500/10000: \tTrain loss: 1.5013 \tVal loss: 1.5143 \tVal acc: 45.08% \t(sec/b=0.019, cuda=3.393G)\n",
            "Train 0600/10000: \tTrain loss: 1.2910 \tVal loss: 1.4243 \tVal acc: 48.43% \t(sec/b=0.019, cuda=3.393G)\n",
            "Train 0700/10000: \tTrain loss: 1.4471 \tVal loss: 1.5015 \tVal acc: 45.62% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 0800/10000: \tTrain loss: 1.2477 \tVal loss: 1.3482 \tVal acc: 50.77% \t(sec/b=0.019, cuda=3.393G)\n",
            "Train 0900/10000: \tTrain loss: 1.3618 \tVal loss: 1.3297 \tVal acc: 51.71% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 1000/10000: \tTrain loss: 1.3268 \tVal loss: 1.3114 \tVal acc: 52.34% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 1100/10000: \tTrain loss: 1.3265 \tVal loss: 1.3035 \tVal acc: 52.82% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 1200/10000: \tTrain loss: 1.2378 \tVal loss: 1.2937 \tVal acc: 54.00% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 1300/10000: \tTrain loss: 1.1084 \tVal loss: 1.2661 \tVal acc: 54.78% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 1400/10000: \tTrain loss: 1.1691 \tVal loss: 1.2181 \tVal acc: 56.51% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 1500/10000: \tTrain loss: 1.1941 \tVal loss: 1.1961 \tVal acc: 57.24% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 1600/10000: \tTrain loss: 1.2243 \tVal loss: 1.1783 \tVal acc: 57.73% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 1700/10000: \tTrain loss: 0.9014 \tVal loss: 1.1642 \tVal acc: 58.02% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 1800/10000: \tTrain loss: 1.3088 \tVal loss: 1.1841 \tVal acc: 57.02% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 1900/10000: \tTrain loss: 1.1051 \tVal loss: 1.1385 \tVal acc: 59.09% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 2000/10000: \tTrain loss: 1.0746 \tVal loss: 1.1452 \tVal acc: 59.01% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 2100/10000: \tTrain loss: 0.9622 \tVal loss: 1.1247 \tVal acc: 60.03% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 2200/10000: \tTrain loss: 1.0398 \tVal loss: 1.1219 \tVal acc: 60.62% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 2300/10000: \tTrain loss: 1.2368 \tVal loss: 1.1163 \tVal acc: 60.04% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 2400/10000: \tTrain loss: 1.2249 \tVal loss: 1.1175 \tVal acc: 60.57% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 2500/10000: \tTrain loss: 0.9676 \tVal loss: 1.0528 \tVal acc: 62.65% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 2600/10000: \tTrain loss: 1.1556 \tVal loss: 1.0367 \tVal acc: 64.01% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 2700/10000: \tTrain loss: 1.1285 \tVal loss: 1.0829 \tVal acc: 61.41% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 2800/10000: \tTrain loss: 0.9780 \tVal loss: 1.0173 \tVal acc: 64.09% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 2900/10000: \tTrain loss: 1.0290 \tVal loss: 1.0401 \tVal acc: 63.31% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 3000/10000: \tTrain loss: 1.0703 \tVal loss: 1.0286 \tVal acc: 63.45% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 3100/10000: \tTrain loss: 1.0597 \tVal loss: 1.0332 \tVal acc: 63.30% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 3200/10000: \tTrain loss: 0.9593 \tVal loss: 1.0030 \tVal acc: 64.60% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 3300/10000: \tTrain loss: 0.9974 \tVal loss: 0.9963 \tVal acc: 64.49% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 3400/10000: \tTrain loss: 1.0568 \tVal loss: 1.0285 \tVal acc: 63.88% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 3500/10000: \tTrain loss: 0.8866 \tVal loss: 0.9905 \tVal acc: 65.12% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 3600/10000: \tTrain loss: 0.8937 \tVal loss: 0.9960 \tVal acc: 65.34% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 3700/10000: \tTrain loss: 0.9473 \tVal loss: 0.9897 \tVal acc: 65.01% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 3800/10000: \tTrain loss: 1.0638 \tVal loss: 0.9731 \tVal acc: 66.37% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 3900/10000: \tTrain loss: 0.9429 \tVal loss: 0.9832 \tVal acc: 65.28% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 4000/10000: \tTrain loss: 0.9607 \tVal loss: 0.9710 \tVal acc: 65.89% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 4100/10000: \tTrain loss: 0.9772 \tVal loss: 0.9814 \tVal acc: 64.99% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 4200/10000: \tTrain loss: 0.9399 \tVal loss: 0.9522 \tVal acc: 66.86% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 4300/10000: \tTrain loss: 0.9861 \tVal loss: 0.9562 \tVal acc: 66.41% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 4400/10000: \tTrain loss: 1.0336 \tVal loss: 1.0010 \tVal acc: 65.08% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 4500/10000: \tTrain loss: 0.8981 \tVal loss: 0.9223 \tVal acc: 67.97% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 4600/10000: \tTrain loss: 0.8419 \tVal loss: 0.9575 \tVal acc: 66.05% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 4700/10000: \tTrain loss: 0.8817 \tVal loss: 1.0003 \tVal acc: 64.76% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 4800/10000: \tTrain loss: 0.7753 \tVal loss: 0.9164 \tVal acc: 68.21% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 4900/10000: \tTrain loss: 1.0365 \tVal loss: 0.9090 \tVal acc: 68.13% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 5000/10000: \tTrain loss: 0.9277 \tVal loss: 0.9111 \tVal acc: 68.80% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 5100/10000: \tTrain loss: 0.8804 \tVal loss: 0.9155 \tVal acc: 67.80% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 5200/10000: \tTrain loss: 0.8625 \tVal loss: 0.9383 \tVal acc: 67.35% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 5300/10000: \tTrain loss: 0.7375 \tVal loss: 0.9510 \tVal acc: 66.76% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 5400/10000: \tTrain loss: 0.9368 \tVal loss: 0.9444 \tVal acc: 66.76% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 5500/10000: \tTrain loss: 0.8244 \tVal loss: 0.9066 \tVal acc: 68.71% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 5600/10000: \tTrain loss: 0.8369 \tVal loss: 0.9051 \tVal acc: 68.39% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 5700/10000: \tTrain loss: 0.8578 \tVal loss: 0.8803 \tVal acc: 69.09% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 5800/10000: \tTrain loss: 0.8286 \tVal loss: 0.8644 \tVal acc: 70.02% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 5900/10000: \tTrain loss: 0.8716 \tVal loss: 0.9173 \tVal acc: 67.51% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 6000/10000: \tTrain loss: 0.7882 \tVal loss: 0.8922 \tVal acc: 69.00% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 6100/10000: \tTrain loss: 0.7931 \tVal loss: 0.8615 \tVal acc: 70.24% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 6200/10000: \tTrain loss: 0.6659 \tVal loss: 0.9287 \tVal acc: 67.34% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 6300/10000: \tTrain loss: 0.8060 \tVal loss: 0.8702 \tVal acc: 69.81% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 6400/10000: \tTrain loss: 0.7950 \tVal loss: 0.8858 \tVal acc: 69.00% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 6500/10000: \tTrain loss: 0.7927 \tVal loss: 0.9047 \tVal acc: 69.02% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 6600/10000: \tTrain loss: 0.8837 \tVal loss: 0.8812 \tVal acc: 69.36% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 6700/10000: \tTrain loss: 0.7833 \tVal loss: 0.8682 \tVal acc: 70.14% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 6800/10000: \tTrain loss: 0.7423 \tVal loss: 0.8487 \tVal acc: 71.00% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 6900/10000: \tTrain loss: 0.7871 \tVal loss: 0.8597 \tVal acc: 69.97% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 7000/10000: \tTrain loss: 0.8957 \tVal loss: 0.8700 \tVal acc: 69.91% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 7100/10000: \tTrain loss: 0.7065 \tVal loss: 0.8691 \tVal acc: 69.60% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 7200/10000: \tTrain loss: 0.7002 \tVal loss: 0.8528 \tVal acc: 70.24% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 7300/10000: \tTrain loss: 0.8427 \tVal loss: 0.8458 \tVal acc: 70.36% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 7400/10000: \tTrain loss: 0.7921 \tVal loss: 0.8561 \tVal acc: 70.40% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 7500/10000: \tTrain loss: 0.7163 \tVal loss: 0.8875 \tVal acc: 69.48% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 7600/10000: \tTrain loss: 0.8228 \tVal loss: 0.8334 \tVal acc: 70.73% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 7700/10000: \tTrain loss: 0.7877 \tVal loss: 0.8590 \tVal acc: 69.79% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 7800/10000: \tTrain loss: 0.8208 \tVal loss: 0.8470 \tVal acc: 71.04% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 7900/10000: \tTrain loss: 0.7505 \tVal loss: 0.8612 \tVal acc: 70.10% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 8000/10000: \tTrain loss: 0.7299 \tVal loss: 0.8559 \tVal acc: 70.67% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 8100/10000: \tTrain loss: 0.8480 \tVal loss: 0.8413 \tVal acc: 70.71% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 8200/10000: \tTrain loss: 0.8120 \tVal loss: 0.8466 \tVal acc: 70.55% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 8300/10000: \tTrain loss: 0.7936 \tVal loss: 0.8404 \tVal acc: 70.75% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 8400/10000: \tTrain loss: 0.8832 \tVal loss: 0.8493 \tVal acc: 70.81% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 8500/10000: \tTrain loss: 0.5914 \tVal loss: 0.8735 \tVal acc: 70.13% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 8600/10000: \tTrain loss: 0.8037 \tVal loss: 0.8167 \tVal acc: 71.81% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 8700/10000: \tTrain loss: 0.6964 \tVal loss: 0.8377 \tVal acc: 71.29% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 8800/10000: \tTrain loss: 0.7037 \tVal loss: 0.8275 \tVal acc: 71.77% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 8900/10000: \tTrain loss: 0.7700 \tVal loss: 0.8356 \tVal acc: 71.07% \t(sec/b=0.018, cuda=3.393G)\n",
            "Train 9000/10000: \tTrain loss: 0.8011 \tVal loss: 0.8226 \tVal acc: 71.65% \t(sec/b=0.018, cuda=3.393G)\n",
            "\n",
            "Reached target accuracy of 72.62%>=72.50% in 9076 steps (162.4439 seconds)\n",
            "esults/step_9076.pt at epoch=25, step=100, completed_steps=9076\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train_vision.py --task C10-32 --head \"gru\" --nino_ckpt_gru \"../nino_gru_head_ctx5_hor40.pt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GHngwMVcAN3",
        "outputId": "6cc03915-8471-4ba3-cd2d-c32ea1ef2db4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Environment:\n",
            "git commit          : 1ae2c09\n",
            "hostname            : 10d1e8aed3f2\n",
            "torch               : 2.5.1+cu121\n",
            "torchvision         : 0.20.1+cu121\n",
            "transformers        : 4.46.3\n",
            "cuda available      : True\n",
            "cudnn enabled       : True\n",
            "cuda version        : 12.1\n",
            "start time          : 20241209-173407\n",
            "\n",
            "Script Arguments:\n",
            "batch_size          : 128\n",
            "checkpointing_steps : None\n",
            "device              : cuda\n",
            "env                 : {'git commit': '1ae2c09', 'hostname': '10d1e8aed3f2', 'torch': '2.5.1+cu121', 'torchvision': '0.20.1+cu121', 'transformers': '4.46.3', 'cuda available': True, 'cudnn enabled': True, 'cuda version': '12.1', 'start time': '20241209-173407'}\n",
            "head                : gru\n",
            "log_interval        : 100\n",
            "lr                  : None\n",
            "max_train_steps     : 10000\n",
            "nino_ckpt_gru       : ../nino_gru_head_ctx5_hor40.pt\n",
            "nino_ckpt_hybrid    : ../nino_hybrid_head_ctx10_hor40.pt\n",
            "nino_ckpt_lstm      : ../nino_lstm_ctx10_head_ctx10_hor40.pt\n",
            "nino_ckpt_mlp       : ../nino_mlp_head_ctx10_hor40.pt\n",
            "num_workers         : 4\n",
            "output_dir          : ..\results\n",
            "period              : 1000\n",
            "resume_from_checkpoi: None\n",
            "seed                : 1000\n",
            "task                : C10-32\n",
            "verbose             : 1\n",
            "wd                  : 0\n",
            "\n",
            "\n",
            "task {'net_args': {'hid': (32, 64, 64), 'in_channels': 3, 'num_classes': 10}, 'dataset': 'CIFAR10', 'norm': ((0.49139968, 0.48215827, 0.44653124), (0.24703233, 0.24348505, 0.26158768)), 'lr': 0.003, 'target': 72.5}\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Net(\n",
            "  (fc): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "    (5): ReLU()\n",
            "    (6): AdaptiveAvgPool2d(output_size=1)\n",
            "    (7): Flatten(start_dim=1, end_dim=-1)\n",
            "    (8): Linear(in_features=64, out_features=10, bias=True)\n",
            "  )\n",
            ") params 56970 total param norm 7.6108598709106445\n",
            "base optimizer AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.003\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "/content/nino/optim/nino.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(ckpt, map_location=self.nino_device)\n",
            "\n",
            "\n",
            "kwargs {'dms_head': 'gru', 'ctx': 5, 'lpe': 8, 'seq_len': 40, 'max_feat_size': 9, 'wte_pos_enc': False, 'positional_encoding': 'learnable', 'dms_transformer_num_heads': 4, 'dms_mlp_num_layers': 2, 'dms_gru_num_layers': 2, 'dms_lstm_num_layers': 2, 'dms_transformer_num_layers': 2, 'add_edge_lpe': False}\n",
            "USING GRU HEAD\n",
            "NiNoModel(\n",
            "  (layer_embed): Embedding(15, 128)\n",
            "  (edge_proj): MLP(\n",
            "    (fc): Sequential(\n",
            "      (0): Linear(in_features=45, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (node_proj): MLP(\n",
            "    (fc): Sequential(\n",
            "      (0): Linear(in_features=8, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (gnn): PNA(\n",
            "    (act): SiLU()\n",
            "    (convs): ModuleList(\n",
            "      (0-2): 3 x PNAConv(128, 128)\n",
            "    )\n",
            "    (edge_update): ModuleList(\n",
            "      (0-1): 2 x EdgeMLP(\n",
            "        (lin_e): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (lin_s): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (lin_t): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (act): SiLU()\n",
            "        (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (edge_out): GRU_DMS(\n",
            "    (gru): GRU(128, 128, num_layers=2, batch_first=True)\n",
            "    (mlp): MLP(\n",
            "      (fc): Sequential(\n",
            "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (1): SiLU()\n",
            "        (2): Linear(in_features=128, out_features=360, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (activation): SiLU()\n",
            "  )\n",
            ")\n",
            "NiNo with 748136 params loaded from step 5000, ckpt file ../nino_gru_head_ctx5_hor40.pt: <All keys matched successfully>\n",
            "\n",
            "k_schedule values (direct multi-step forecasting) = [40 33 26 21 16 11  8  5  3  1]\n",
            "2024-12-09 17:34:13.471406: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-09 17:34:13.489660: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-09 17:34:13.512667: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-09 17:34:13.519314: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-09 17:34:13.535701: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-09 17:34:14.862996: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Computing Laplacian positional encoding (LPE) for k=8...\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/data/storage.py:452: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'edge_type', 'edge_index', 'pos_w'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
            "  warnings.warn(\n",
            "\n",
            "Neural graph for \"Net\" (NeuralGraph) constructed in 0.012 sec:\n",
            "NeuralGraph(\n",
            "  num_nodes=177,\n",
            "  num_edges=7227,\n",
            "  edge_index=torch.Size([2, 7227]),\n",
            "  has_self_loops=True,\n",
            "  pos (LPE)=torch.Size([177, 8])\n",
            ")\n",
            "\n",
            "Training C10-32 with 359 batches per epoch for 28 epochs\n",
            "Train 0100/10000: \tTrain loss: 1.8269 \tVal loss: 1.7810 \tVal acc: 31.76% \t(sec/b=0.023, cuda=3.395G)\n",
            "step 200, add state #1, mem on cuda:0=3.395G, cpu=1.788G\n",
            "Train 0200/10000: \tTrain loss: 1.7200 \tVal loss: 1.6796 \tVal acc: 37.36% \t(sec/b=0.020, cuda=3.395G)\n",
            "Train 0300/10000: \tTrain loss: 1.6287 \tVal loss: 1.6228 \tVal acc: 40.80% \t(sec/b=0.019, cuda=3.395G)\n",
            "step 400, add state #2, mem on cuda:0=3.395G, cpu=1.852G\n",
            "Train 0400/10000: \tTrain loss: 1.4526 \tVal loss: 1.5304 \tVal acc: 44.00% \t(sec/b=0.020, cuda=3.395G)\n",
            "Train 0500/10000: \tTrain loss: 1.5021 \tVal loss: 1.5142 \tVal acc: 45.08% \t(sec/b=0.019, cuda=3.395G)\n",
            "step 600, add state #3, mem on cuda:0=3.395G, cpu=1.850G\n",
            "Train 0600/10000: \tTrain loss: 1.2913 \tVal loss: 1.4258 \tVal acc: 48.38% \t(sec/b=0.019, cuda=3.395G)\n",
            "Train 0700/10000: \tTrain loss: 1.4483 \tVal loss: 1.4991 \tVal acc: 45.73% \t(sec/b=0.019, cuda=3.395G)\n",
            "step 800, add state #4, mem on cuda:0=3.397G, cpu=1.852G\n",
            "Train 0800/10000: \tTrain loss: 1.2467 \tVal loss: 1.3496 \tVal acc: 50.72% \t(sec/b=0.019, cuda=3.397G)\n",
            "Train 0900/10000: \tTrain loss: 1.3635 \tVal loss: 1.3288 \tVal acc: 51.82% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1000, add state #5, mem on cuda:0=3.397G, cpu=1.851G\n",
            "loss before NiNo step: 1.3321\n",
            "\n",
            "NiNo step starting at step 1000 (k=40): peak mem on cuda:0=3.397G, cpu=1.851G\n",
            "creating edge_attr with shape (7227, 45) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.579 sec, peak mem on cuda:0=3.397G, cpu=1.980G\n",
            "\n",
            "loss after NiNo step: 7.3026\n",
            "Train 1000/10000: \tTrain loss: 7.3026 \tVal loss: 7.6655 \tVal acc: 12.34% \t(sec/b=0.019, cuda=3.397G)\n",
            "Train 1100/10000: \tTrain loss: 1.6849 \tVal loss: 1.5889 \tVal acc: 40.63% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1200, add state #1, mem on cuda:0=3.397G, cpu=1.981G\n",
            "Train 1200/10000: \tTrain loss: 1.4459 \tVal loss: 1.5212 \tVal acc: 43.82% \t(sec/b=0.019, cuda=3.397G)\n",
            "Train 1300/10000: \tTrain loss: 1.2928 \tVal loss: 1.4033 \tVal acc: 49.12% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1400, add state #2, mem on cuda:0=3.397G, cpu=1.980G\n",
            "Train 1400/10000: \tTrain loss: 1.3137 \tVal loss: 1.3621 \tVal acc: 50.23% \t(sec/b=0.019, cuda=3.397G)\n",
            "Train 1500/10000: \tTrain loss: 1.3443 \tVal loss: 1.3150 \tVal acc: 52.49% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1600, add state #3, mem on cuda:0=3.397G, cpu=1.981G\n",
            "Train 1600/10000: \tTrain loss: 1.3531 \tVal loss: 1.2938 \tVal acc: 53.19% \t(sec/b=0.019, cuda=3.397G)\n",
            "Train 1700/10000: \tTrain loss: 1.0144 \tVal loss: 1.2567 \tVal acc: 54.11% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1800, add state #4, mem on cuda:0=3.397G, cpu=1.981G\n",
            "Train 1800/10000: \tTrain loss: 1.2787 \tVal loss: 1.2469 \tVal acc: 54.99% \t(sec/b=0.019, cuda=3.397G)\n",
            "Train 1900/10000: \tTrain loss: 1.2207 \tVal loss: 1.2063 \tVal acc: 56.51% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 2000, add state #5, mem on cuda:0=3.397G, cpu=1.980G\n",
            "loss before NiNo step: 1.1111\n",
            "\n",
            "NiNo step starting at step 2000 (k=33): peak mem on cuda:0=3.368G, cpu=1.980G\n",
            "creating edge_attr with shape (7227, 45) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.021 sec, peak mem on cuda:0=3.368G, cpu=1.981G\n",
            "\n",
            "loss after NiNo step: 3.2650\n",
            "Train 2000/10000: \tTrain loss: 3.2650 \tVal loss: 3.2160 \tVal acc: 16.18% \t(sec/b=0.019, cuda=3.368G)\n",
            "Train 2100/10000: \tTrain loss: 1.3035 \tVal loss: 1.3400 \tVal acc: 51.89% \t(sec/b=0.019, cuda=3.368G)\n",
            "step 2200, add state #1, mem on cuda:0=3.368G, cpu=1.982G\n",
            "Train 2200/10000: \tTrain loss: 1.1587 \tVal loss: 1.2759 \tVal acc: 54.21% \t(sec/b=0.019, cuda=3.368G)\n",
            "Train 2300/10000: \tTrain loss: 1.3266 \tVal loss: 1.2373 \tVal acc: 55.26% \t(sec/b=0.019, cuda=3.368G)\n",
            "step 2400, add state #2, mem on cuda:0=3.368G, cpu=1.980G\n",
            "Train 2400/10000: \tTrain loss: 1.2962 \tVal loss: 1.2646 \tVal acc: 55.50% \t(sec/b=0.019, cuda=3.368G)\n",
            "Train 2500/10000: \tTrain loss: 1.0942 \tVal loss: 1.1602 \tVal acc: 58.73% \t(sec/b=0.019, cuda=3.368G)\n",
            "step 2600, add state #3, mem on cuda:0=3.368G, cpu=1.982G\n",
            "Train 2600/10000: \tTrain loss: 1.1128 \tVal loss: 1.1235 \tVal acc: 60.18% \t(sec/b=0.019, cuda=3.368G)\n",
            "Train 2700/10000: \tTrain loss: 1.2610 \tVal loss: 1.1180 \tVal acc: 60.38% \t(sec/b=0.019, cuda=3.368G)\n",
            "step 2800, add state #4, mem on cuda:0=3.368G, cpu=1.980G\n",
            "Train 2800/10000: \tTrain loss: 1.0489 \tVal loss: 1.0925 \tVal acc: 61.39% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 2900/10000: \tTrain loss: 1.1270 \tVal loss: 1.1071 \tVal acc: 60.99% \t(sec/b=0.019, cuda=3.368G)\n",
            "step 3000, add state #5, mem on cuda:0=3.368G, cpu=1.982G\n",
            "loss before NiNo step: 1.1519\n",
            "\n",
            "NiNo step starting at step 3000 (k=26): peak mem on cuda:0=3.368G, cpu=1.982G\n",
            "creating edge_attr with shape (7227, 45) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.024 sec, peak mem on cuda:0=3.368G, cpu=1.982G\n",
            "\n",
            "loss after NiNo step: 3.2997\n",
            "Train 3000/10000: \tTrain loss: 3.2997 \tVal loss: 3.0927 \tVal acc: 26.39% \t(sec/b=0.019, cuda=3.368G)\n",
            "Train 3100/10000: \tTrain loss: 1.3132 \tVal loss: 1.1735 \tVal acc: 58.18% \t(sec/b=0.019, cuda=3.368G)\n",
            "step 3200, add state #1, mem on cuda:0=3.368G, cpu=1.980G\n",
            "Train 3200/10000: \tTrain loss: 1.0721 \tVal loss: 1.1209 \tVal acc: 59.59% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 3300/10000: \tTrain loss: 1.1547 \tVal loss: 1.1111 \tVal acc: 61.04% \t(sec/b=0.019, cuda=3.368G)\n",
            "step 3400, add state #2, mem on cuda:0=3.368G, cpu=1.982G\n",
            "Train 3400/10000: \tTrain loss: 1.1001 \tVal loss: 1.0885 \tVal acc: 61.41% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 3500/10000: \tTrain loss: 0.9967 \tVal loss: 1.0413 \tVal acc: 63.10% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 3600, add state #3, mem on cuda:0=3.368G, cpu=1.982G\n",
            "Train 3600/10000: \tTrain loss: 0.9888 \tVal loss: 1.0812 \tVal acc: 61.78% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 3700/10000: \tTrain loss: 1.0122 \tVal loss: 1.0204 \tVal acc: 63.58% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 3800, add state #4, mem on cuda:0=3.368G, cpu=1.980G\n",
            "Train 3800/10000: \tTrain loss: 1.2464 \tVal loss: 1.0190 \tVal acc: 64.11% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 3900/10000: \tTrain loss: 1.0664 \tVal loss: 0.9989 \tVal acc: 64.76% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 4000, add state #5, mem on cuda:0=3.368G, cpu=1.982G\n",
            "loss before NiNo step: 1.0697\n",
            "\n",
            "NiNo step starting at step 4000 (k=21): peak mem on cuda:0=3.368G, cpu=1.982G\n",
            "creating edge_attr with shape (7227, 45) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.022 sec, peak mem on cuda:0=3.368G, cpu=1.982G\n",
            "\n",
            "loss after NiNo step: 2.2466\n",
            "Train 4000/10000: \tTrain loss: 2.2466 \tVal loss: 2.4923 \tVal acc: 32.65% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 4100/10000: \tTrain loss: 1.1641 \tVal loss: 1.0824 \tVal acc: 61.21% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 4200, add state #1, mem on cuda:0=3.368G, cpu=1.980G\n",
            "Train 4200/10000: \tTrain loss: 1.0432 \tVal loss: 1.0417 \tVal acc: 62.98% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 4300/10000: \tTrain loss: 1.0578 \tVal loss: 1.0111 \tVal acc: 63.75% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 4400, add state #2, mem on cuda:0=3.368G, cpu=1.982G\n",
            "Train 4400/10000: \tTrain loss: 1.1414 \tVal loss: 1.0460 \tVal acc: 63.05% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 4500/10000: \tTrain loss: 1.0001 \tVal loss: 0.9629 \tVal acc: 65.98% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 4600, add state #3, mem on cuda:0=3.368G, cpu=1.981G\n",
            "Train 4600/10000: \tTrain loss: 0.9383 \tVal loss: 0.9804 \tVal acc: 65.33% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 4700/10000: \tTrain loss: 0.8706 \tVal loss: 0.9927 \tVal acc: 65.23% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 4800, add state #4, mem on cuda:0=3.368G, cpu=1.982G\n",
            "Train 4800/10000: \tTrain loss: 0.8889 \tVal loss: 0.9649 \tVal acc: 66.17% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 4900/10000: \tTrain loss: 1.0747 \tVal loss: 0.9396 \tVal acc: 66.79% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 5000, add state #5, mem on cuda:0=3.368G, cpu=1.981G\n",
            "loss before NiNo step: 0.9213\n",
            "\n",
            "NiNo step starting at step 5000 (k=16): peak mem on cuda:0=3.368G, cpu=1.981G\n",
            "creating edge_attr with shape (7227, 45) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.022 sec, peak mem on cuda:0=3.368G, cpu=1.982G\n",
            "\n",
            "loss after NiNo step: 2.1580\n",
            "Train 5000/10000: \tTrain loss: 2.1580 \tVal loss: 2.2802 \tVal acc: 31.91% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 5100/10000: \tTrain loss: 0.8846 \tVal loss: 0.9747 \tVal acc: 65.28% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 5200, add state #1, mem on cuda:0=3.368G, cpu=1.982G\n",
            "Train 5200/10000: \tTrain loss: 1.0053 \tVal loss: 0.9672 \tVal acc: 66.12% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 5300/10000: \tTrain loss: 0.8002 \tVal loss: 0.9604 \tVal acc: 66.26% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 5400, add state #2, mem on cuda:0=3.368G, cpu=1.982G\n",
            "Train 5400/10000: \tTrain loss: 0.9897 \tVal loss: 0.9840 \tVal acc: 65.40% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 5500/10000: \tTrain loss: 0.9198 \tVal loss: 0.9229 \tVal acc: 67.22% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 5600, add state #3, mem on cuda:0=3.368G, cpu=1.981G\n",
            "Train 5600/10000: \tTrain loss: 0.9084 \tVal loss: 0.9236 \tVal acc: 66.92% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 5700/10000: \tTrain loss: 0.9108 \tVal loss: 0.9279 \tVal acc: 67.50% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 5800, add state #4, mem on cuda:0=3.368G, cpu=1.982G\n",
            "Train 5800/10000: \tTrain loss: 0.8700 \tVal loss: 0.8942 \tVal acc: 68.35% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 5900/10000: \tTrain loss: 0.9262 \tVal loss: 0.9622 \tVal acc: 66.22% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 6000, add state #5, mem on cuda:0=3.368G, cpu=1.981G\n",
            "loss before NiNo step: 0.8352\n",
            "\n",
            "NiNo step starting at step 6000 (k=11): peak mem on cuda:0=3.368G, cpu=1.981G\n",
            "creating edge_attr with shape (7227, 45) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.023 sec, peak mem on cuda:0=3.368G, cpu=1.982G\n",
            "\n",
            "loss after NiNo step: 1.7959\n",
            "Train 6000/10000: \tTrain loss: 1.7959 \tVal loss: 1.7978 \tVal acc: 43.87% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 6100/10000: \tTrain loss: 0.8578 \tVal loss: 0.9229 \tVal acc: 67.66% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 6200, add state #1, mem on cuda:0=3.368G, cpu=1.982G\n",
            "Train 6200/10000: \tTrain loss: 0.7247 \tVal loss: 0.9344 \tVal acc: 67.33% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 6300/10000: \tTrain loss: 0.8138 \tVal loss: 0.9151 \tVal acc: 68.24% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 6400, add state #2, mem on cuda:0=3.368G, cpu=1.981G\n",
            "Train 6400/10000: \tTrain loss: 0.8676 \tVal loss: 0.9173 \tVal acc: 68.18% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 6500/10000: \tTrain loss: 0.7668 \tVal loss: 0.9372 \tVal acc: 66.79% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 6600, add state #3, mem on cuda:0=3.368G, cpu=1.982G\n",
            "Train 6600/10000: \tTrain loss: 0.8707 \tVal loss: 0.8875 \tVal acc: 69.06% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 6700/10000: \tTrain loss: 0.8010 \tVal loss: 0.9208 \tVal acc: 68.33% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 6800, add state #4, mem on cuda:0=3.368G, cpu=1.981G\n",
            "Train 6800/10000: \tTrain loss: 0.6968 \tVal loss: 0.8694 \tVal acc: 69.68% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 6900/10000: \tTrain loss: 0.7825 \tVal loss: 0.9072 \tVal acc: 68.45% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 7000, add state #5, mem on cuda:0=3.368G, cpu=1.982G\n",
            "loss before NiNo step: 0.9010\n",
            "\n",
            "NiNo step starting at step 7000 (k=8): peak mem on cuda:0=3.368G, cpu=1.982G\n",
            "creating edge_attr with shape (7227, 45) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.022 sec, peak mem on cuda:0=3.368G, cpu=1.982G\n",
            "\n",
            "loss after NiNo step: 1.7949\n",
            "Train 7000/10000: \tTrain loss: 1.7949 \tVal loss: 1.8191 \tVal acc: 44.98% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 7100/10000: \tTrain loss: 0.7010 \tVal loss: 0.9574 \tVal acc: 66.52% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 7200, add state #1, mem on cuda:0=3.368G, cpu=1.982G\n",
            "Train 7200/10000: \tTrain loss: 0.8449 \tVal loss: 0.9274 \tVal acc: 67.92% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 7300/10000: \tTrain loss: 0.8074 \tVal loss: 0.8862 \tVal acc: 69.37% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 7400, add state #2, mem on cuda:0=3.368G, cpu=1.981G\n",
            "Train 7400/10000: \tTrain loss: 0.8214 \tVal loss: 0.9068 \tVal acc: 68.29% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 7500/10000: \tTrain loss: 0.7263 \tVal loss: 0.9155 \tVal acc: 68.38% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 7600, add state #3, mem on cuda:0=3.368G, cpu=1.982G\n",
            "Train 7600/10000: \tTrain loss: 0.6841 \tVal loss: 0.8656 \tVal acc: 69.69% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 7700/10000: \tTrain loss: 0.7761 \tVal loss: 0.9053 \tVal acc: 68.14% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 7800, add state #4, mem on cuda:0=3.368G, cpu=1.981G\n",
            "Train 7800/10000: \tTrain loss: 0.8431 \tVal loss: 0.8753 \tVal acc: 69.36% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 7900/10000: \tTrain loss: 0.8141 \tVal loss: 0.9631 \tVal acc: 66.39% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 8000, add state #5, mem on cuda:0=3.368G, cpu=1.982G\n",
            "loss before NiNo step: 0.7994\n",
            "\n",
            "NiNo step starting at step 8000 (k=5): peak mem on cuda:0=3.368G, cpu=1.982G\n",
            "creating edge_attr with shape (7227, 45) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.023 sec, peak mem on cuda:0=3.368G, cpu=1.982G\n",
            "\n",
            "loss after NiNo step: 1.5327\n",
            "Train 8000/10000: \tTrain loss: 1.5327 \tVal loss: 1.6266 \tVal acc: 51.00% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 8100/10000: \tTrain loss: 0.7888 \tVal loss: 0.9057 \tVal acc: 68.62% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 8200, add state #1, mem on cuda:0=3.368G, cpu=1.981G\n",
            "Train 8200/10000: \tTrain loss: 0.8248 \tVal loss: 0.8895 \tVal acc: 69.11% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 8300/10000: \tTrain loss: 0.9311 \tVal loss: 0.8791 \tVal acc: 69.69% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 8400, add state #2, mem on cuda:0=3.368G, cpu=1.982G\n",
            "Train 8400/10000: \tTrain loss: 0.8272 \tVal loss: 0.9302 \tVal acc: 68.26% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 8500/10000: \tTrain loss: 0.6095 \tVal loss: 0.9128 \tVal acc: 68.50% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 8600, add state #3, mem on cuda:0=3.368G, cpu=1.981G\n",
            "Train 8600/10000: \tTrain loss: 0.8649 \tVal loss: 0.8843 \tVal acc: 68.96% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 8700/10000: \tTrain loss: 0.6345 \tVal loss: 0.8872 \tVal acc: 69.16% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 8800, add state #4, mem on cuda:0=3.368G, cpu=1.982G\n",
            "Train 8800/10000: \tTrain loss: 0.6716 \tVal loss: 0.8597 \tVal acc: 70.40% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 8900/10000: \tTrain loss: 0.6989 \tVal loss: 0.8732 \tVal acc: 70.29% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 9000, add state #5, mem on cuda:0=3.368G, cpu=1.982G\n",
            "loss before NiNo step: 0.7740\n",
            "\n",
            "NiNo step starting at step 9000 (k=3): peak mem on cuda:0=3.368G, cpu=1.982G\n",
            "creating edge_attr with shape (7227, 45) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.022 sec, peak mem on cuda:0=3.368G, cpu=1.982G\n",
            "\n",
            "loss after NiNo step: 1.4960\n",
            "Train 9000/10000: \tTrain loss: 1.4960 \tVal loss: 1.3994 \tVal acc: 55.57% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 9100/10000: \tTrain loss: 0.5394 \tVal loss: 0.8792 \tVal acc: 69.45% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 9200, add state #1, mem on cuda:0=3.368G, cpu=1.981G\n",
            "Train 9200/10000: \tTrain loss: 0.5533 \tVal loss: 0.8555 \tVal acc: 70.49% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 9300/10000: \tTrain loss: 0.6887 \tVal loss: 0.8569 \tVal acc: 70.54% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 9400, add state #2, mem on cuda:0=3.368G, cpu=1.982G\n",
            "Train 9400/10000: \tTrain loss: 0.5922 \tVal loss: 0.8876 \tVal acc: 69.63% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 9500/10000: \tTrain loss: 0.6725 \tVal loss: 0.9123 \tVal acc: 68.41% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 9600, add state #3, mem on cuda:0=3.368G, cpu=1.981G\n",
            "Train 9600/10000: \tTrain loss: 0.4901 \tVal loss: 0.8673 \tVal acc: 70.25% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 9700/10000: \tTrain loss: 0.5254 \tVal loss: 0.9340 \tVal acc: 68.21% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 9800, add state #4, mem on cuda:0=3.368G, cpu=1.982G\n",
            "Train 9800/10000: \tTrain loss: 0.6141 \tVal loss: 0.8550 \tVal acc: 70.74% \t(sec/b=0.018, cuda=3.368G)\n",
            "Train 9900/10000: \tTrain loss: 0.6744 \tVal loss: 0.8751 \tVal acc: 69.73% \t(sec/b=0.018, cuda=3.368G)\n",
            "step 10000, add state #5, mem on cuda:0=3.368G, cpu=1.981G\n",
            "loss before NiNo step: 0.6705\n",
            "\n",
            "NiNo step starting at step 10000 (k=1): peak mem on cuda:0=3.368G, cpu=1.981G\n",
            "creating edge_attr with shape (7227, 45) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.025 sec, peak mem on cuda:0=3.368G, cpu=1.982G\n",
            "\n",
            "loss after NiNo step: 0.9486\n",
            "Train 10000/10000: \tTrain loss: 0.9486 \tVal loss: 1.1308 \tVal acc: 64.14% \t(sec/b=0.018, cuda=3.368G)\n",
            "esults/step_10000.pt at epoch=27, step=306, completed_steps=10000\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train_vision.py --task C10-32 --head \"gru\" --nino_ckpt_gru \"../nino_gru_head_ctx10_hor40.pt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7rQjXdSdkU1",
        "outputId": "5574f1a8-50b7-4a6d-cf8f-e30b9bafd2ee"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Environment:\n",
            "git commit          : 1ae2c09\n",
            "hostname            : 10d1e8aed3f2\n",
            "torch               : 2.5.1+cu121\n",
            "torchvision         : 0.20.1+cu121\n",
            "transformers        : 4.46.3\n",
            "cuda available      : True\n",
            "cudnn enabled       : True\n",
            "cuda version        : 12.1\n",
            "start time          : 20241209-173725\n",
            "\n",
            "Script Arguments:\n",
            "batch_size          : 128\n",
            "checkpointing_steps : None\n",
            "device              : cuda\n",
            "env                 : {'git commit': '1ae2c09', 'hostname': '10d1e8aed3f2', 'torch': '2.5.1+cu121', 'torchvision': '0.20.1+cu121', 'transformers': '4.46.3', 'cuda available': True, 'cudnn enabled': True, 'cuda version': '12.1', 'start time': '20241209-173725'}\n",
            "head                : gru\n",
            "log_interval        : 100\n",
            "lr                  : None\n",
            "max_train_steps     : 10000\n",
            "nino_ckpt_gru       : ../nino_gru_head_ctx10_hor40.pt\n",
            "nino_ckpt_hybrid    : ../nino_hybrid_head_ctx10_hor40.pt\n",
            "nino_ckpt_lstm      : ../nino_lstm_ctx10_head_ctx10_hor40.pt\n",
            "nino_ckpt_mlp       : ../nino_mlp_head_ctx10_hor40.pt\n",
            "num_workers         : 4\n",
            "output_dir          : ..\results\n",
            "period              : 1000\n",
            "resume_from_checkpoi: None\n",
            "seed                : 1000\n",
            "task                : C10-32\n",
            "verbose             : 1\n",
            "wd                  : 0\n",
            "\n",
            "\n",
            "task {'net_args': {'hid': (32, 64, 64), 'in_channels': 3, 'num_classes': 10}, 'dataset': 'CIFAR10', 'norm': ((0.49139968, 0.48215827, 0.44653124), (0.24703233, 0.24348505, 0.26158768)), 'lr': 0.003, 'target': 72.5}\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Net(\n",
            "  (fc): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "    (5): ReLU()\n",
            "    (6): AdaptiveAvgPool2d(output_size=1)\n",
            "    (7): Flatten(start_dim=1, end_dim=-1)\n",
            "    (8): Linear(in_features=64, out_features=10, bias=True)\n",
            "  )\n",
            ") params 56970 total param norm 7.6108598709106445\n",
            "base optimizer AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.003\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "/content/nino/optim/nino.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(ckpt, map_location=self.nino_device)\n",
            "\n",
            "\n",
            "kwargs {'dms_head': 'gru', 'ctx': 10, 'lpe': 8, 'seq_len': 40, 'max_feat_size': 9, 'wte_pos_enc': False, 'positional_encoding': 'learnable', 'dms_transformer_num_heads': 4, 'dms_mlp_num_layers': 2, 'dms_gru_num_layers': 2, 'dms_lstm_num_layers': 2, 'dms_transformer_num_layers': 2, 'add_edge_lpe': False}\n",
            "USING GRU HEAD\n",
            "NiNoModel(\n",
            "  (layer_embed): Embedding(15, 128)\n",
            "  (edge_proj): MLP(\n",
            "    (fc): Sequential(\n",
            "      (0): Linear(in_features=90, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (node_proj): MLP(\n",
            "    (fc): Sequential(\n",
            "      (0): Linear(in_features=8, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (gnn): PNA(\n",
            "    (act): SiLU()\n",
            "    (convs): ModuleList(\n",
            "      (0-2): 3 x PNAConv(128, 128)\n",
            "    )\n",
            "    (edge_update): ModuleList(\n",
            "      (0-1): 2 x EdgeMLP(\n",
            "        (lin_e): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (lin_s): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (lin_t): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (act): SiLU()\n",
            "        (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (edge_out): GRU_DMS(\n",
            "    (gru): GRU(128, 128, num_layers=2, batch_first=True)\n",
            "    (mlp): MLP(\n",
            "      (fc): Sequential(\n",
            "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (1): SiLU()\n",
            "        (2): Linear(in_features=128, out_features=360, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (activation): SiLU()\n",
            "  )\n",
            ")\n",
            "NiNo with 753896 params loaded from step 5000, ckpt file ../nino_gru_head_ctx10_hor40.pt: <All keys matched successfully>\n",
            "\n",
            "k_schedule values (direct multi-step forecasting) = [40 33 26 21 16 11  8  5  3  1]\n",
            "2024-12-09 17:37:31.433426: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-09 17:37:31.451266: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-09 17:37:31.473417: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-09 17:37:31.479976: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-09 17:37:31.495388: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-09 17:37:32.841498: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Computing Laplacian positional encoding (LPE) for k=8...\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/data/storage.py:452: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'edge_type', 'pos_w', 'edge_index'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
            "  warnings.warn(\n",
            "\n",
            "Neural graph for \"Net\" (NeuralGraph) constructed in 0.011 sec:\n",
            "NeuralGraph(\n",
            "  num_nodes=177,\n",
            "  num_edges=7227,\n",
            "  edge_index=torch.Size([2, 7227]),\n",
            "  has_self_loops=True,\n",
            "  pos (LPE)=torch.Size([177, 8])\n",
            ")\n",
            "\n",
            "Training C10-32 with 359 batches per epoch for 28 epochs\n",
            "step 100, add state #1, mem on cuda:0=3.395G, cpu=1.789G\n",
            "Train 0100/10000: \tTrain loss: 1.8269 \tVal loss: 1.7810 \tVal acc: 31.76% \t(sec/b=0.023, cuda=3.395G)\n",
            "step 200, add state #2, mem on cuda:0=3.395G, cpu=1.787G\n",
            "Train 0200/10000: \tTrain loss: 1.7200 \tVal loss: 1.6796 \tVal acc: 37.36% \t(sec/b=0.021, cuda=3.395G)\n",
            "step 300, add state #3, mem on cuda:0=3.395G, cpu=1.787G\n",
            "Train 0300/10000: \tTrain loss: 1.6287 \tVal loss: 1.6228 \tVal acc: 40.80% \t(sec/b=0.020, cuda=3.395G)\n",
            "step 400, add state #4, mem on cuda:0=3.397G, cpu=1.852G\n",
            "Train 0400/10000: \tTrain loss: 1.4526 \tVal loss: 1.5304 \tVal acc: 44.00% \t(sec/b=0.020, cuda=3.397G)\n",
            "step 500, add state #5, mem on cuda:0=3.397G, cpu=1.851G\n",
            "Train 0500/10000: \tTrain loss: 1.5016 \tVal loss: 1.5143 \tVal acc: 45.15% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 600, add state #6, mem on cuda:0=3.397G, cpu=1.851G\n",
            "Train 0600/10000: \tTrain loss: 1.2915 \tVal loss: 1.4250 \tVal acc: 48.37% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 700, add state #7, mem on cuda:0=3.397G, cpu=1.851G\n",
            "Train 0700/10000: \tTrain loss: 1.4440 \tVal loss: 1.4979 \tVal acc: 45.75% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 800, add state #8, mem on cuda:0=3.397G, cpu=1.852G\n",
            "Train 0800/10000: \tTrain loss: 1.2363 \tVal loss: 1.3460 \tVal acc: 50.99% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 900, add state #9, mem on cuda:0=3.397G, cpu=1.851G\n",
            "Train 0900/10000: \tTrain loss: 1.3610 \tVal loss: 1.3305 \tVal acc: 51.77% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1000, add state #10, mem on cuda:0=3.397G, cpu=1.851G\n",
            "loss before NiNo step: 1.3282\n",
            "\n",
            "NiNo step starting at step 1000 (k=40): peak mem on cuda:0=3.397G, cpu=1.851G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.669 sec, peak mem on cuda:0=3.397G, cpu=1.980G\n",
            "\n",
            "loss after NiNo step: 2.5761\n",
            "Train 1000/10000: \tTrain loss: 2.5761 \tVal loss: 2.5180 \tVal acc: 24.90% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1100, add state #1, mem on cuda:0=3.397G, cpu=1.982G\n",
            "Train 1100/10000: \tTrain loss: 1.3824 \tVal loss: 1.3253 \tVal acc: 51.97% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1200, add state #2, mem on cuda:0=3.397G, cpu=1.980G\n",
            "Train 1200/10000: \tTrain loss: 1.2252 \tVal loss: 1.2962 \tVal acc: 54.04% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1300, add state #3, mem on cuda:0=3.397G, cpu=1.980G\n",
            "Train 1300/10000: \tTrain loss: 1.0981 \tVal loss: 1.2501 \tVal acc: 55.04% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1400, add state #4, mem on cuda:0=3.397G, cpu=1.980G\n",
            "Train 1400/10000: \tTrain loss: 1.2223 \tVal loss: 1.2261 \tVal acc: 56.14% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1500, add state #5, mem on cuda:0=3.397G, cpu=1.982G\n",
            "Train 1500/10000: \tTrain loss: 1.1613 \tVal loss: 1.2074 \tVal acc: 56.73% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1600, add state #6, mem on cuda:0=3.397G, cpu=1.980G\n",
            "Train 1600/10000: \tTrain loss: 1.2277 \tVal loss: 1.1740 \tVal acc: 58.12% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1700, add state #7, mem on cuda:0=3.397G, cpu=1.980G\n",
            "Train 1700/10000: \tTrain loss: 0.9486 \tVal loss: 1.1911 \tVal acc: 57.25% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1800, add state #8, mem on cuda:0=3.397G, cpu=1.982G\n",
            "Train 1800/10000: \tTrain loss: 1.2483 \tVal loss: 1.1766 \tVal acc: 57.47% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1900, add state #9, mem on cuda:0=3.397G, cpu=1.980G\n",
            "Train 1900/10000: \tTrain loss: 1.1577 \tVal loss: 1.1487 \tVal acc: 58.83% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 2000, add state #10, mem on cuda:0=3.397G, cpu=1.980G\n",
            "loss before NiNo step: 1.0236\n",
            "\n",
            "NiNo step starting at step 2000 (k=33): peak mem on cuda:0=3.385G, cpu=1.980G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.022 sec, peak mem on cuda:0=3.385G, cpu=1.982G\n",
            "\n",
            "loss after NiNo step: 1.7501\n",
            "Train 2000/10000: \tTrain loss: 1.7501 \tVal loss: 1.8424 \tVal acc: 33.17% \t(sec/b=0.019, cuda=3.385G)\n",
            "step 2100, add state #1, mem on cuda:0=3.385G, cpu=1.981G\n",
            "Train 2100/10000: \tTrain loss: 1.0371 \tVal loss: 1.1819 \tVal acc: 57.87% \t(sec/b=0.019, cuda=3.385G)\n",
            "step 2200, add state #2, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 2200/10000: \tTrain loss: 1.0377 \tVal loss: 1.1400 \tVal acc: 59.55% \t(sec/b=0.019, cuda=3.385G)\n",
            "step 2300, add state #3, mem on cuda:0=3.385G, cpu=1.981G\n",
            "Train 2300/10000: \tTrain loss: 1.2466 \tVal loss: 1.1343 \tVal acc: 59.17% \t(sec/b=0.019, cuda=3.385G)\n",
            "step 2400, add state #4, mem on cuda:0=3.385G, cpu=1.981G\n",
            "Train 2400/10000: \tTrain loss: 1.2409 \tVal loss: 1.1275 \tVal acc: 59.76% \t(sec/b=0.019, cuda=3.385G)\n",
            "step 2500, add state #5, mem on cuda:0=3.385G, cpu=1.981G\n",
            "Train 2500/10000: \tTrain loss: 0.9964 \tVal loss: 1.0613 \tVal acc: 62.10% \t(sec/b=0.019, cuda=3.385G)\n",
            "step 2600, add state #6, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 2600/10000: \tTrain loss: 1.1150 \tVal loss: 1.0553 \tVal acc: 63.04% \t(sec/b=0.019, cuda=3.385G)\n",
            "step 2700, add state #7, mem on cuda:0=3.385G, cpu=1.981G\n",
            "Train 2700/10000: \tTrain loss: 1.1443 \tVal loss: 1.1031 \tVal acc: 60.92% \t(sec/b=0.019, cuda=3.385G)\n",
            "step 2800, add state #8, mem on cuda:0=3.385G, cpu=1.981G\n",
            "Train 2800/10000: \tTrain loss: 1.0396 \tVal loss: 1.0454 \tVal acc: 63.31% \t(sec/b=0.019, cuda=3.385G)\n",
            "step 2900, add state #9, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 2900/10000: \tTrain loss: 1.1014 \tVal loss: 1.0670 \tVal acc: 62.50% \t(sec/b=0.019, cuda=3.385G)\n",
            "step 3000, add state #10, mem on cuda:0=3.385G, cpu=1.981G\n",
            "loss before NiNo step: 1.1437\n",
            "\n",
            "NiNo step starting at step 3000 (k=26): peak mem on cuda:0=3.385G, cpu=1.981G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.022 sec, peak mem on cuda:0=3.385G, cpu=1.983G\n",
            "\n",
            "loss after NiNo step: 1.6810\n",
            "Train 3000/10000: \tTrain loss: 1.6810 \tVal loss: 1.7330 \tVal acc: 38.06% \t(sec/b=0.019, cuda=3.385G)\n",
            "step 3100, add state #1, mem on cuda:0=3.385G, cpu=1.981G\n",
            "Train 3100/10000: \tTrain loss: 1.0844 \tVal loss: 1.0644 \tVal acc: 62.42% \t(sec/b=0.019, cuda=3.385G)\n",
            "step 3200, add state #2, mem on cuda:0=3.385G, cpu=1.981G\n",
            "Train 3200/10000: \tTrain loss: 1.0215 \tVal loss: 1.0538 \tVal acc: 62.82% \t(sec/b=0.019, cuda=3.385G)\n",
            "step 3300, add state #3, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 3300/10000: \tTrain loss: 1.0164 \tVal loss: 1.0318 \tVal acc: 63.32% \t(sec/b=0.019, cuda=3.385G)\n",
            "step 3400, add state #4, mem on cuda:0=3.385G, cpu=1.981G\n",
            "Train 3400/10000: \tTrain loss: 1.0345 \tVal loss: 1.0261 \tVal acc: 64.27% \t(sec/b=0.019, cuda=3.385G)\n",
            "step 3500, add state #5, mem on cuda:0=3.385G, cpu=1.981G\n",
            "Train 3500/10000: \tTrain loss: 0.8818 \tVal loss: 1.0067 \tVal acc: 64.99% \t(sec/b=0.019, cuda=3.385G)\n",
            "step 3600, add state #6, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 3600/10000: \tTrain loss: 0.8920 \tVal loss: 1.0377 \tVal acc: 63.37% \t(sec/b=0.019, cuda=3.385G)\n",
            "step 3700, add state #7, mem on cuda:0=3.385G, cpu=1.981G\n",
            "Train 3700/10000: \tTrain loss: 0.9716 \tVal loss: 0.9877 \tVal acc: 64.96% \t(sec/b=0.019, cuda=3.385G)\n",
            "step 3800, add state #8, mem on cuda:0=3.385G, cpu=1.981G\n",
            "Train 3800/10000: \tTrain loss: 1.1555 \tVal loss: 0.9991 \tVal acc: 65.30% \t(sec/b=0.019, cuda=3.385G)\n",
            "step 3900, add state #9, mem on cuda:0=3.385G, cpu=1.981G\n",
            "Train 3900/10000: \tTrain loss: 0.9475 \tVal loss: 0.9823 \tVal acc: 65.44% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 4000, add state #10, mem on cuda:0=3.387G, cpu=1.983G\n",
            "loss before NiNo step: 0.9376\n",
            "\n",
            "NiNo step starting at step 4000 (k=21): peak mem on cuda:0=3.387G, cpu=1.983G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.023 sec, peak mem on cuda:0=3.387G, cpu=1.983G\n",
            "\n",
            "loss after NiNo step: 1.9408\n",
            "Train 4000/10000: \tTrain loss: 1.9408 \tVal loss: 2.0655 \tVal acc: 33.20% \t(sec/b=0.019, cuda=3.387G)\n",
            "step 4100, add state #1, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 4100/10000: \tTrain loss: 0.9915 \tVal loss: 1.0318 \tVal acc: 63.66% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4200, add state #2, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 4200/10000: \tTrain loss: 0.8703 \tVal loss: 0.9892 \tVal acc: 65.22% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4300, add state #3, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 4300/10000: \tTrain loss: 0.9878 \tVal loss: 0.9916 \tVal acc: 65.17% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4400, add state #4, mem on cuda:0=3.387G, cpu=1.983G\n",
            "Train 4400/10000: \tTrain loss: 0.9904 \tVal loss: 0.9931 \tVal acc: 65.11% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4500, add state #5, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 4500/10000: \tTrain loss: 0.9513 \tVal loss: 0.9417 \tVal acc: 66.95% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4600, add state #6, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 4600/10000: \tTrain loss: 0.8314 \tVal loss: 0.9618 \tVal acc: 66.39% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4700, add state #7, mem on cuda:0=3.387G, cpu=1.983G\n",
            "Train 4700/10000: \tTrain loss: 0.7869 \tVal loss: 0.9757 \tVal acc: 65.62% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4800, add state #8, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 4800/10000: \tTrain loss: 0.7776 \tVal loss: 0.9319 \tVal acc: 67.59% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4900, add state #9, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 4900/10000: \tTrain loss: 1.0672 \tVal loss: 0.9127 \tVal acc: 67.76% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 5000, add state #10, mem on cuda:0=3.387G, cpu=1.982G\n",
            "loss before NiNo step: 0.9578\n",
            "\n",
            "NiNo step starting at step 5000 (k=16): peak mem on cuda:0=3.385G, cpu=1.982G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.025 sec, peak mem on cuda:0=3.385G, cpu=1.983G\n",
            "\n",
            "loss after NiNo step: 1.6935\n",
            "Train 5000/10000: \tTrain loss: 1.6935 \tVal loss: 1.6413 \tVal acc: 44.97% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5100, add state #1, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 5100/10000: \tTrain loss: 0.8535 \tVal loss: 0.9543 \tVal acc: 66.30% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5200, add state #2, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 5200/10000: \tTrain loss: 0.8570 \tVal loss: 0.9748 \tVal acc: 66.02% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5300, add state #3, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 5300/10000: \tTrain loss: 0.6914 \tVal loss: 0.9456 \tVal acc: 67.38% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5400, add state #4, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 5400/10000: \tTrain loss: 0.9272 \tVal loss: 0.9750 \tVal acc: 65.94% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5500, add state #5, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 5500/10000: \tTrain loss: 0.8304 \tVal loss: 0.9052 \tVal acc: 68.60% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5600, add state #6, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 5600/10000: \tTrain loss: 0.8950 \tVal loss: 0.9104 \tVal acc: 68.16% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5700, add state #7, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 5700/10000: \tTrain loss: 0.8343 \tVal loss: 0.9118 \tVal acc: 68.24% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5800, add state #8, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 5800/10000: \tTrain loss: 0.9073 \tVal loss: 0.8793 \tVal acc: 69.98% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5900, add state #9, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 5900/10000: \tTrain loss: 0.9058 \tVal loss: 0.9479 \tVal acc: 67.17% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6000, add state #10, mem on cuda:0=3.385G, cpu=1.982G\n",
            "loss before NiNo step: 0.7086\n",
            "\n",
            "NiNo step starting at step 6000 (k=11): peak mem on cuda:0=3.385G, cpu=1.982G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.026 sec, peak mem on cuda:0=3.385G, cpu=1.983G\n",
            "\n",
            "loss after NiNo step: 1.7469\n",
            "Train 6000/10000: \tTrain loss: 1.7469 \tVal loss: 1.8251 \tVal acc: 42.34% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6100, add state #1, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 6100/10000: \tTrain loss: 0.8311 \tVal loss: 0.9106 \tVal acc: 68.29% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6200, add state #2, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 6200/10000: \tTrain loss: 0.6969 \tVal loss: 0.9802 \tVal acc: 65.98% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6300, add state #3, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 6300/10000: \tTrain loss: 0.8317 \tVal loss: 0.8972 \tVal acc: 69.23% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6400, add state #4, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 6400/10000: \tTrain loss: 0.8492 \tVal loss: 0.9473 \tVal acc: 66.72% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6500, add state #5, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 6500/10000: \tTrain loss: 0.7485 \tVal loss: 0.9749 \tVal acc: 66.68% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6600, add state #6, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 6600/10000: \tTrain loss: 0.7817 \tVal loss: 0.8887 \tVal acc: 69.53% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6700, add state #7, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 6700/10000: \tTrain loss: 0.7857 \tVal loss: 0.9024 \tVal acc: 68.82% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6800, add state #8, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 6800/10000: \tTrain loss: 0.6860 \tVal loss: 0.8676 \tVal acc: 70.18% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6900, add state #9, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 6900/10000: \tTrain loss: 0.7948 \tVal loss: 0.8881 \tVal acc: 69.46% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7000, add state #10, mem on cuda:0=3.385G, cpu=1.982G\n",
            "loss before NiNo step: 0.9242\n",
            "\n",
            "NiNo step starting at step 7000 (k=8): peak mem on cuda:0=3.385G, cpu=1.982G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.025 sec, peak mem on cuda:0=3.385G, cpu=1.983G\n",
            "\n",
            "loss after NiNo step: 1.4696\n",
            "Train 7000/10000: \tTrain loss: 1.4696 \tVal loss: 1.5176 \tVal acc: 52.41% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7100, add state #1, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 7100/10000: \tTrain loss: 0.7142 \tVal loss: 0.9126 \tVal acc: 68.50% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7200, add state #2, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 7200/10000: \tTrain loss: 0.7972 \tVal loss: 0.8967 \tVal acc: 69.09% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7300, add state #3, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 7300/10000: \tTrain loss: 0.8518 \tVal loss: 0.8810 \tVal acc: 69.39% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7400, add state #4, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 7400/10000: \tTrain loss: 0.8166 \tVal loss: 0.8966 \tVal acc: 69.81% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7500, add state #5, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 7500/10000: \tTrain loss: 0.6827 \tVal loss: 0.8929 \tVal acc: 69.45% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7600, add state #6, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 7600/10000: \tTrain loss: 0.7214 \tVal loss: 0.8630 \tVal acc: 70.14% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7700, add state #7, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 7700/10000: \tTrain loss: 0.7801 \tVal loss: 0.8877 \tVal acc: 69.29% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7800, add state #8, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 7800/10000: \tTrain loss: 0.7993 \tVal loss: 0.8741 \tVal acc: 69.70% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7900, add state #9, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 7900/10000: \tTrain loss: 0.7581 \tVal loss: 0.8895 \tVal acc: 69.58% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 8000, add state #10, mem on cuda:0=3.385G, cpu=1.982G\n",
            "loss before NiNo step: 0.7118\n",
            "\n",
            "NiNo step starting at step 8000 (k=5): peak mem on cuda:0=3.385G, cpu=1.982G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.024 sec, peak mem on cuda:0=3.385G, cpu=1.983G\n",
            "\n",
            "loss after NiNo step: 1.0949\n",
            "Train 8000/10000: \tTrain loss: 1.0949 \tVal loss: 1.2283 \tVal acc: 58.63% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 8100, add state #1, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 8100/10000: \tTrain loss: 0.6957 \tVal loss: 0.8562 \tVal acc: 70.17% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 8200, add state #2, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 8200/10000: \tTrain loss: 0.7375 \tVal loss: 0.8807 \tVal acc: 69.62% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 8300, add state #3, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 8300/10000: \tTrain loss: 0.8663 \tVal loss: 0.8816 \tVal acc: 70.13% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 8400, add state #4, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 8400/10000: \tTrain loss: 0.8016 \tVal loss: 0.8800 \tVal acc: 70.02% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 8500, add state #5, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 8500/10000: \tTrain loss: 0.6236 \tVal loss: 0.8765 \tVal acc: 70.61% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 8600, add state #6, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 8600/10000: \tTrain loss: 0.7232 \tVal loss: 0.8551 \tVal acc: 70.69% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 8700, add state #7, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 8700/10000: \tTrain loss: 0.6731 \tVal loss: 0.8735 \tVal acc: 69.99% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 8800, add state #8, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 8800/10000: \tTrain loss: 0.7078 \tVal loss: 0.8644 \tVal acc: 70.38% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 8900, add state #9, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 8900/10000: \tTrain loss: 0.7119 \tVal loss: 0.8550 \tVal acc: 70.93% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 9000, add state #10, mem on cuda:0=3.385G, cpu=1.984G\n",
            "loss before NiNo step: 0.7269\n",
            "\n",
            "NiNo step starting at step 9000 (k=3): peak mem on cuda:0=3.385G, cpu=1.984G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.024 sec, peak mem on cuda:0=3.385G, cpu=1.984G\n",
            "\n",
            "loss after NiNo step: 0.9201\n",
            "Train 9000/10000: \tTrain loss: 0.9201 \tVal loss: 0.9988 \tVal acc: 65.50% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 9100, add state #1, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 9100/10000: \tTrain loss: 0.5213 \tVal loss: 0.8782 \tVal acc: 69.98% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 9200, add state #2, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 9200/10000: \tTrain loss: 0.6144 \tVal loss: 0.8578 \tVal acc: 71.00% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 9300, add state #3, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 9300/10000: \tTrain loss: 0.6633 \tVal loss: 0.8896 \tVal acc: 70.41% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 9400, add state #4, mem on cuda:0=3.385G, cpu=1.984G\n",
            "Train 9400/10000: \tTrain loss: 0.5108 \tVal loss: 0.8742 \tVal acc: 70.57% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 9500, add state #5, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 9500/10000: \tTrain loss: 0.5267 \tVal loss: 0.8723 \tVal acc: 70.12% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 9600, add state #6, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 9600/10000: \tTrain loss: 0.5958 \tVal loss: 0.8754 \tVal acc: 70.54% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 9700, add state #7, mem on cuda:0=3.385G, cpu=1.984G\n",
            "Train 9700/10000: \tTrain loss: 0.5610 \tVal loss: 0.8661 \tVal acc: 70.25% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 9800, add state #8, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 9800/10000: \tTrain loss: 0.5842 \tVal loss: 0.8622 \tVal acc: 70.62% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 9900, add state #9, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 9900/10000: \tTrain loss: 0.6639 \tVal loss: 0.8528 \tVal acc: 70.86% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 10000, add state #10, mem on cuda:0=3.385G, cpu=1.982G\n",
            "loss before NiNo step: 0.5949\n",
            "\n",
            "NiNo step starting at step 10000 (k=1): peak mem on cuda:0=3.385G, cpu=1.982G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.024 sec, peak mem on cuda:0=3.385G, cpu=1.984G\n",
            "\n",
            "loss after NiNo step: 0.7840\n",
            "Train 10000/10000: \tTrain loss: 0.7840 \tVal loss: 1.0385 \tVal acc: 65.09% \t(sec/b=0.018, cuda=3.385G)\n",
            "esults/step_10000.pt at epoch=27, step=306, completed_steps=10000\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train_vision.py --task C10-32 --head \"gru\" --nino_ckpt_gru \"../nino_gru_head_ctx10_hor100.pt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LO7LlieglTH",
        "outputId": "9aa1b1e0-2cfe-4371-cbf4-80f369749b40"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Environment:\n",
            "git commit          : 1ae2c09\n",
            "hostname            : 10d1e8aed3f2\n",
            "torch               : 2.5.1+cu121\n",
            "torchvision         : 0.20.1+cu121\n",
            "transformers        : 4.46.3\n",
            "cuda available      : True\n",
            "cudnn enabled       : True\n",
            "cuda version        : 12.1\n",
            "start time          : 20241209-174110\n",
            "\n",
            "Script Arguments:\n",
            "batch_size          : 128\n",
            "checkpointing_steps : None\n",
            "device              : cuda\n",
            "env                 : {'git commit': '1ae2c09', 'hostname': '10d1e8aed3f2', 'torch': '2.5.1+cu121', 'torchvision': '0.20.1+cu121', 'transformers': '4.46.3', 'cuda available': True, 'cudnn enabled': True, 'cuda version': '12.1', 'start time': '20241209-174110'}\n",
            "head                : gru\n",
            "log_interval        : 100\n",
            "lr                  : None\n",
            "max_train_steps     : 10000\n",
            "nino_ckpt_gru       : ../nino_gru_head_ctx10_hor100.pt\n",
            "nino_ckpt_hybrid    : ../nino_hybrid_head_ctx10_hor40.pt\n",
            "nino_ckpt_lstm      : ../nino_lstm_ctx10_head_ctx10_hor40.pt\n",
            "nino_ckpt_mlp       : ../nino_mlp_head_ctx10_hor40.pt\n",
            "num_workers         : 4\n",
            "output_dir          : ..\results\n",
            "period              : 1000\n",
            "resume_from_checkpoi: None\n",
            "seed                : 1000\n",
            "task                : C10-32\n",
            "verbose             : 1\n",
            "wd                  : 0\n",
            "\n",
            "\n",
            "task {'net_args': {'hid': (32, 64, 64), 'in_channels': 3, 'num_classes': 10}, 'dataset': 'CIFAR10', 'norm': ((0.49139968, 0.48215827, 0.44653124), (0.24703233, 0.24348505, 0.26158768)), 'lr': 0.003, 'target': 72.5}\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Net(\n",
            "  (fc): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "    (5): ReLU()\n",
            "    (6): AdaptiveAvgPool2d(output_size=1)\n",
            "    (7): Flatten(start_dim=1, end_dim=-1)\n",
            "    (8): Linear(in_features=64, out_features=10, bias=True)\n",
            "  )\n",
            ") params 56970 total param norm 7.6108598709106445\n",
            "base optimizer AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.003\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "/content/nino/optim/nino.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(ckpt, map_location=self.nino_device)\n",
            "\n",
            "\n",
            "kwargs {'dms_head': 'gru', 'ctx': 10, 'lpe': 8, 'seq_len': 100, 'max_feat_size': 9, 'wte_pos_enc': False, 'positional_encoding': 'learnable', 'dms_transformer_num_heads': 4, 'dms_mlp_num_layers': 2, 'dms_gru_num_layers': 2, 'dms_lstm_num_layers': 2, 'dms_transformer_num_layers': 2, 'add_edge_lpe': False}\n",
            "USING GRU HEAD\n",
            "NiNoModel(\n",
            "  (layer_embed): Embedding(15, 128)\n",
            "  (edge_proj): MLP(\n",
            "    (fc): Sequential(\n",
            "      (0): Linear(in_features=90, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (node_proj): MLP(\n",
            "    (fc): Sequential(\n",
            "      (0): Linear(in_features=8, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (gnn): PNA(\n",
            "    (act): SiLU()\n",
            "    (convs): ModuleList(\n",
            "      (0-2): 3 x PNAConv(128, 128)\n",
            "    )\n",
            "    (edge_update): ModuleList(\n",
            "      (0-1): 2 x EdgeMLP(\n",
            "        (lin_e): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (lin_s): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (lin_t): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (act): SiLU()\n",
            "        (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (edge_out): GRU_DMS(\n",
            "    (gru): GRU(128, 128, num_layers=2, batch_first=True)\n",
            "    (mlp): MLP(\n",
            "      (fc): Sequential(\n",
            "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (1): SiLU()\n",
            "        (2): Linear(in_features=128, out_features=900, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (activation): SiLU()\n",
            "  )\n",
            ")\n",
            "NiNo with 823556 params loaded from step 5000, ckpt file ../nino_gru_head_ctx10_hor100.pt: <All keys matched successfully>\n",
            "\n",
            "k_schedule values (direct multi-step forecasting) = [100  81  64  49  36  25  16   9   4   1]\n",
            "2024-12-09 17:41:16.212795: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-09 17:41:16.230375: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-09 17:41:16.252763: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-09 17:41:16.259278: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-09 17:41:16.274951: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-09 17:41:17.606593: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Computing Laplacian positional encoding (LPE) for k=8...\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/data/storage.py:452: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'edge_index', 'pos_w', 'edge_type'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
            "  warnings.warn(\n",
            "\n",
            "Neural graph for \"Net\" (NeuralGraph) constructed in 0.012 sec:\n",
            "NeuralGraph(\n",
            "  num_nodes=177,\n",
            "  num_edges=7227,\n",
            "  edge_index=torch.Size([2, 7227]),\n",
            "  has_self_loops=True,\n",
            "  pos (LPE)=torch.Size([177, 8])\n",
            ")\n",
            "\n",
            "Training C10-32 with 359 batches per epoch for 28 epochs\n",
            "step 100, add state #1, mem on cuda:0=3.395G, cpu=1.789G\n",
            "Train 0100/10000: \tTrain loss: 1.8269 \tVal loss: 1.7810 \tVal acc: 31.76% \t(sec/b=0.024, cuda=3.395G)\n",
            "step 200, add state #2, mem on cuda:0=3.395G, cpu=1.787G\n",
            "Train 0200/10000: \tTrain loss: 1.7200 \tVal loss: 1.6796 \tVal acc: 37.36% \t(sec/b=0.021, cuda=3.395G)\n",
            "step 300, add state #3, mem on cuda:0=3.395G, cpu=1.787G\n",
            "Train 0300/10000: \tTrain loss: 1.6287 \tVal loss: 1.6228 \tVal acc: 40.80% \t(sec/b=0.020, cuda=3.395G)\n",
            "step 400, add state #4, mem on cuda:0=3.397G, cpu=1.853G\n",
            "Train 0400/10000: \tTrain loss: 1.4526 \tVal loss: 1.5304 \tVal acc: 43.98% \t(sec/b=0.020, cuda=3.397G)\n",
            "step 500, add state #5, mem on cuda:0=3.397G, cpu=1.851G\n",
            "Train 0500/10000: \tTrain loss: 1.5022 \tVal loss: 1.5142 \tVal acc: 45.07% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 600, add state #6, mem on cuda:0=3.397G, cpu=1.851G\n",
            "Train 0600/10000: \tTrain loss: 1.2896 \tVal loss: 1.4242 \tVal acc: 48.32% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 700, add state #7, mem on cuda:0=3.397G, cpu=1.851G\n",
            "Train 0700/10000: \tTrain loss: 1.4448 \tVal loss: 1.4987 \tVal acc: 45.69% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 800, add state #8, mem on cuda:0=3.397G, cpu=1.853G\n",
            "Train 0800/10000: \tTrain loss: 1.2353 \tVal loss: 1.3441 \tVal acc: 51.22% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 900, add state #9, mem on cuda:0=3.397G, cpu=1.851G\n",
            "Train 0900/10000: \tTrain loss: 1.3624 \tVal loss: 1.3333 \tVal acc: 51.72% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1000, add state #10, mem on cuda:0=3.397G, cpu=1.851G\n",
            "loss before NiNo step: 1.3304\n",
            "\n",
            "NiNo step starting at step 1000 (k=100): peak mem on cuda:0=3.397G, cpu=1.851G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.557 sec, peak mem on cuda:0=3.397G, cpu=1.981G\n",
            "\n",
            "loss after NiNo step: 1.3569\n",
            "Train 1000/10000: \tTrain loss: 1.3569 \tVal loss: 1.3157 \tVal acc: 52.21% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1100, add state #1, mem on cuda:0=3.397G, cpu=1.982G\n",
            "Train 1100/10000: \tTrain loss: 1.3322 \tVal loss: 1.3016 \tVal acc: 53.02% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1200, add state #2, mem on cuda:0=3.397G, cpu=1.981G\n",
            "Train 1200/10000: \tTrain loss: 1.2359 \tVal loss: 1.2870 \tVal acc: 54.18% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1300, add state #3, mem on cuda:0=3.397G, cpu=1.981G\n",
            "Train 1300/10000: \tTrain loss: 1.1092 \tVal loss: 1.2670 \tVal acc: 54.91% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1400, add state #4, mem on cuda:0=3.397G, cpu=1.981G\n",
            "Train 1400/10000: \tTrain loss: 1.1433 \tVal loss: 1.2121 \tVal acc: 56.71% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1500, add state #5, mem on cuda:0=3.397G, cpu=1.982G\n",
            "Train 1500/10000: \tTrain loss: 1.1888 \tVal loss: 1.2030 \tVal acc: 56.99% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1600, add state #6, mem on cuda:0=3.397G, cpu=1.981G\n",
            "Train 1600/10000: \tTrain loss: 1.2315 \tVal loss: 1.1735 \tVal acc: 58.17% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1700, add state #7, mem on cuda:0=3.397G, cpu=1.981G\n",
            "Train 1700/10000: \tTrain loss: 0.9126 \tVal loss: 1.1693 \tVal acc: 57.81% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1800, add state #8, mem on cuda:0=3.397G, cpu=1.982G\n",
            "Train 1800/10000: \tTrain loss: 1.2940 \tVal loss: 1.1824 \tVal acc: 57.02% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1900, add state #9, mem on cuda:0=3.397G, cpu=1.981G\n",
            "Train 1900/10000: \tTrain loss: 1.0967 \tVal loss: 1.1377 \tVal acc: 59.12% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 2000, add state #10, mem on cuda:0=3.397G, cpu=1.981G\n",
            "loss before NiNo step: 1.0639\n",
            "\n",
            "NiNo step starting at step 2000 (k=81): peak mem on cuda:0=3.385G, cpu=1.981G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.022 sec, peak mem on cuda:0=3.385G, cpu=1.983G\n",
            "\n",
            "loss after NiNo step: 1.0553\n",
            "Train 2000/10000: \tTrain loss: 1.0553 \tVal loss: 1.1526 \tVal acc: 58.86% \t(sec/b=0.019, cuda=3.385G)\n",
            "step 2100, add state #1, mem on cuda:0=3.385G, cpu=1.981G\n",
            "Train 2100/10000: \tTrain loss: 0.9665 \tVal loss: 1.1295 \tVal acc: 59.75% \t(sec/b=0.019, cuda=3.385G)\n",
            "step 2200, add state #2, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 2200/10000: \tTrain loss: 1.0408 \tVal loss: 1.1279 \tVal acc: 60.14% \t(sec/b=0.019, cuda=3.385G)\n",
            "step 2300, add state #3, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 2300/10000: \tTrain loss: 1.2016 \tVal loss: 1.1263 \tVal acc: 59.17% \t(sec/b=0.019, cuda=3.385G)\n",
            "step 2400, add state #4, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 2400/10000: \tTrain loss: 1.1932 \tVal loss: 1.1257 \tVal acc: 60.47% \t(sec/b=0.019, cuda=3.385G)\n",
            "step 2500, add state #5, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 2500/10000: \tTrain loss: 0.9856 \tVal loss: 1.0607 \tVal acc: 62.10% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 2600, add state #6, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 2600/10000: \tTrain loss: 1.1301 \tVal loss: 1.0402 \tVal acc: 63.46% \t(sec/b=0.019, cuda=3.385G)\n",
            "step 2700, add state #7, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 2700/10000: \tTrain loss: 1.1353 \tVal loss: 1.0755 \tVal acc: 61.98% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 2800, add state #8, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 2800/10000: \tTrain loss: 1.0005 \tVal loss: 1.0249 \tVal acc: 64.06% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 2900, add state #9, mem on cuda:0=3.387G, cpu=1.983G\n",
            "Train 2900/10000: \tTrain loss: 1.0292 \tVal loss: 1.0386 \tVal acc: 63.68% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 3000, add state #10, mem on cuda:0=3.387G, cpu=1.982G\n",
            "loss before NiNo step: 1.0373\n",
            "\n",
            "NiNo step starting at step 3000 (k=64): peak mem on cuda:0=3.387G, cpu=1.982G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.025 sec, peak mem on cuda:0=3.387G, cpu=1.983G\n",
            "\n",
            "loss after NiNo step: 1.0678\n",
            "Train 3000/10000: \tTrain loss: 1.0678 \tVal loss: 1.0521 \tVal acc: 62.96% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 3100, add state #1, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 3100/10000: \tTrain loss: 1.0504 \tVal loss: 1.0191 \tVal acc: 63.90% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 3200, add state #2, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 3200/10000: \tTrain loss: 0.9838 \tVal loss: 1.0115 \tVal acc: 64.49% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 3300, add state #3, mem on cuda:0=3.387G, cpu=1.983G\n",
            "Train 3300/10000: \tTrain loss: 1.0193 \tVal loss: 1.0020 \tVal acc: 64.72% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 3400, add state #4, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 3400/10000: \tTrain loss: 1.0579 \tVal loss: 1.0404 \tVal acc: 63.52% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 3500, add state #5, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 3500/10000: \tTrain loss: 0.9014 \tVal loss: 0.9944 \tVal acc: 65.33% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 3600, add state #6, mem on cuda:0=3.387G, cpu=1.983G\n",
            "Train 3600/10000: \tTrain loss: 0.9109 \tVal loss: 0.9938 \tVal acc: 65.29% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 3700, add state #7, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 3700/10000: \tTrain loss: 0.9850 \tVal loss: 0.9939 \tVal acc: 65.23% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 3800, add state #8, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 3800/10000: \tTrain loss: 1.1253 \tVal loss: 0.9819 \tVal acc: 66.36% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 3900, add state #9, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 3900/10000: \tTrain loss: 0.9405 \tVal loss: 0.9781 \tVal acc: 65.70% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4000, add state #10, mem on cuda:0=3.387G, cpu=1.983G\n",
            "loss before NiNo step: 0.9433\n",
            "\n",
            "NiNo step starting at step 4000 (k=49): peak mem on cuda:0=3.387G, cpu=1.983G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.024 sec, peak mem on cuda:0=3.387G, cpu=1.983G\n",
            "\n",
            "loss after NiNo step: 0.9466\n",
            "Train 4000/10000: \tTrain loss: 0.9466 \tVal loss: 0.9979 \tVal acc: 64.85% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4100, add state #1, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 4100/10000: \tTrain loss: 0.9876 \tVal loss: 0.9860 \tVal acc: 65.16% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4200, add state #2, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 4200/10000: \tTrain loss: 0.8986 \tVal loss: 0.9618 \tVal acc: 66.78% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4300, add state #3, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 4300/10000: \tTrain loss: 0.9940 \tVal loss: 0.9711 \tVal acc: 65.78% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4400, add state #4, mem on cuda:0=3.387G, cpu=1.983G\n",
            "Train 4400/10000: \tTrain loss: 1.0556 \tVal loss: 0.9926 \tVal acc: 66.07% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4500, add state #5, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 4500/10000: \tTrain loss: 0.9491 \tVal loss: 0.9353 \tVal acc: 67.35% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4600, add state #6, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 4600/10000: \tTrain loss: 0.8622 \tVal loss: 0.9748 \tVal acc: 66.33% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4700, add state #7, mem on cuda:0=3.387G, cpu=1.983G\n",
            "Train 4700/10000: \tTrain loss: 0.8396 \tVal loss: 1.0160 \tVal acc: 64.34% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4800, add state #8, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 4800/10000: \tTrain loss: 0.7541 \tVal loss: 0.9227 \tVal acc: 68.09% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4900, add state #9, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 4900/10000: \tTrain loss: 1.0720 \tVal loss: 0.9243 \tVal acc: 67.91% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 5000, add state #10, mem on cuda:0=3.387G, cpu=1.982G\n",
            "loss before NiNo step: 0.9440\n",
            "\n",
            "NiNo step starting at step 5000 (k=36): peak mem on cuda:0=3.385G, cpu=1.982G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.025 sec, peak mem on cuda:0=3.385G, cpu=1.983G\n",
            "\n",
            "loss after NiNo step: 2.0152\n",
            "Train 5000/10000: \tTrain loss: 2.0152 \tVal loss: 2.1167 \tVal acc: 34.65% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5100, add state #1, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 5100/10000: \tTrain loss: 0.8450 \tVal loss: 0.9588 \tVal acc: 66.28% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5200, add state #2, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 5200/10000: \tTrain loss: 0.8977 \tVal loss: 0.9394 \tVal acc: 67.14% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5300, add state #3, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 5300/10000: \tTrain loss: 0.7502 \tVal loss: 0.9062 \tVal acc: 68.32% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5400, add state #4, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 5400/10000: \tTrain loss: 0.9232 \tVal loss: 0.9654 \tVal acc: 66.79% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5500, add state #5, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 5500/10000: \tTrain loss: 0.8217 \tVal loss: 0.8960 \tVal acc: 68.98% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5600, add state #6, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 5600/10000: \tTrain loss: 0.8305 \tVal loss: 0.8939 \tVal acc: 68.83% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5700, add state #7, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 5700/10000: \tTrain loss: 0.8187 \tVal loss: 0.8862 \tVal acc: 69.33% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5800, add state #8, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 5800/10000: \tTrain loss: 0.8252 \tVal loss: 0.8713 \tVal acc: 69.84% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5900, add state #9, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 5900/10000: \tTrain loss: 0.8336 \tVal loss: 0.9061 \tVal acc: 68.16% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6000, add state #10, mem on cuda:0=3.385G, cpu=1.982G\n",
            "loss before NiNo step: 0.7394\n",
            "\n",
            "NiNo step starting at step 6000 (k=25): peak mem on cuda:0=3.385G, cpu=1.982G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.024 sec, peak mem on cuda:0=3.385G, cpu=1.983G\n",
            "\n",
            "loss after NiNo step: 1.8226\n",
            "Train 6000/10000: \tTrain loss: 1.8226 \tVal loss: 1.9050 \tVal acc: 38.71% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6100, add state #1, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 6100/10000: \tTrain loss: 0.8156 \tVal loss: 0.9227 \tVal acc: 67.84% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6200, add state #2, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 6200/10000: \tTrain loss: 0.6596 \tVal loss: 0.9247 \tVal acc: 67.68% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6300, add state #3, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 6300/10000: \tTrain loss: 0.8283 \tVal loss: 0.8947 \tVal acc: 69.27% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6400, add state #4, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 6400/10000: \tTrain loss: 0.8892 \tVal loss: 0.9197 \tVal acc: 67.92% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6500, add state #5, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 6500/10000: \tTrain loss: 0.8224 \tVal loss: 0.9227 \tVal acc: 68.54% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6600, add state #6, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 6600/10000: \tTrain loss: 0.8463 \tVal loss: 0.8811 \tVal acc: 69.25% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6700, add state #7, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 6700/10000: \tTrain loss: 0.8313 \tVal loss: 0.8929 \tVal acc: 69.31% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6800, add state #8, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 6800/10000: \tTrain loss: 0.7313 \tVal loss: 0.8558 \tVal acc: 70.72% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6900, add state #9, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 6900/10000: \tTrain loss: 0.7211 \tVal loss: 0.8490 \tVal acc: 70.96% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7000, add state #10, mem on cuda:0=3.385G, cpu=1.982G\n",
            "loss before NiNo step: 0.8906\n",
            "\n",
            "NiNo step starting at step 7000 (k=16): peak mem on cuda:0=3.385G, cpu=1.982G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.023 sec, peak mem on cuda:0=3.385G, cpu=1.983G\n",
            "\n",
            "loss after NiNo step: 1.8914\n",
            "Train 7000/10000: \tTrain loss: 1.8914 \tVal loss: 1.8575 \tVal acc: 44.76% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7100, add state #1, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 7100/10000: \tTrain loss: 0.7138 \tVal loss: 0.8763 \tVal acc: 69.65% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7200, add state #2, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 7200/10000: \tTrain loss: 0.7908 \tVal loss: 0.8629 \tVal acc: 70.21% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7300, add state #3, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 7300/10000: \tTrain loss: 0.8603 \tVal loss: 0.8505 \tVal acc: 70.69% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7400, add state #4, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 7400/10000: \tTrain loss: 0.7794 \tVal loss: 0.8540 \tVal acc: 70.34% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7500, add state #5, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 7500/10000: \tTrain loss: 0.7196 \tVal loss: 0.8727 \tVal acc: 69.89% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7600, add state #6, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 7600/10000: \tTrain loss: 0.7699 \tVal loss: 0.8520 \tVal acc: 70.46% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7700, add state #7, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 7700/10000: \tTrain loss: 0.7727 \tVal loss: 0.8553 \tVal acc: 70.65% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7800, add state #8, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 7800/10000: \tTrain loss: 0.8089 \tVal loss: 0.8533 \tVal acc: 70.52% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7900, add state #9, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 7900/10000: \tTrain loss: 0.7689 \tVal loss: 0.8661 \tVal acc: 70.60% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 8000, add state #10, mem on cuda:0=3.385G, cpu=1.982G\n",
            "loss before NiNo step: 0.7088\n",
            "\n",
            "NiNo step starting at step 8000 (k=9): peak mem on cuda:0=3.385G, cpu=1.982G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.024 sec, peak mem on cuda:0=3.385G, cpu=1.983G\n",
            "\n",
            "loss after NiNo step: 1.8249\n",
            "Train 8000/10000: \tTrain loss: 1.8249 \tVal loss: 1.7936 \tVal acc: 48.44% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 8100, add state #1, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 8100/10000: \tTrain loss: 0.7766 \tVal loss: 0.8457 \tVal acc: 70.72% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 8200, add state #2, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 8200/10000: \tTrain loss: 0.7634 \tVal loss: 0.8428 \tVal acc: 70.96% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 8300, add state #3, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 8300/10000: \tTrain loss: 0.8078 \tVal loss: 0.8245 \tVal acc: 71.71% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 8400, add state #4, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 8400/10000: \tTrain loss: 0.8191 \tVal loss: 0.8594 \tVal acc: 70.69% \t(sec/b=0.018, cuda=3.385G)\n",
            "\n",
            "Reached target accuracy of 72.51%>=72.50% in 8477 steps (154.1310 seconds)\n",
            "esults/step_8477.pt at epoch=23, step=219, completed_steps=8477\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train_vision.py --task C10-32 --head \"gru\" --nino_ckpt_gru \"../nino_gru_head_ctx10_hor200.pt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL1FDGRoiI78",
        "outputId": "049ed843-ab28-4d9a-d8b6-d63b44b4ce66"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Environment:\n",
            "git commit          : 1ae2c09\n",
            "hostname            : 10d1e8aed3f2\n",
            "torch               : 2.5.1+cu121\n",
            "torchvision         : 0.20.1+cu121\n",
            "transformers        : 4.46.3\n",
            "cuda available      : True\n",
            "cudnn enabled       : True\n",
            "cuda version        : 12.1\n",
            "start time          : 20241209-174741\n",
            "\n",
            "Script Arguments:\n",
            "batch_size          : 128\n",
            "checkpointing_steps : None\n",
            "device              : cuda\n",
            "env                 : {'git commit': '1ae2c09', 'hostname': '10d1e8aed3f2', 'torch': '2.5.1+cu121', 'torchvision': '0.20.1+cu121', 'transformers': '4.46.3', 'cuda available': True, 'cudnn enabled': True, 'cuda version': '12.1', 'start time': '20241209-174741'}\n",
            "head                : gru\n",
            "log_interval        : 100\n",
            "lr                  : None\n",
            "max_train_steps     : 10000\n",
            "nino_ckpt_gru       : ../nino_gru_head_ctx10_hor200.pt\n",
            "nino_ckpt_hybrid    : ../nino_hybrid_head_ctx10_hor40.pt\n",
            "nino_ckpt_lstm      : ../nino_lstm_ctx10_head_ctx10_hor40.pt\n",
            "nino_ckpt_mlp       : ../nino_mlp_head_ctx10_hor40.pt\n",
            "num_workers         : 4\n",
            "output_dir          : ..\results\n",
            "period              : 1000\n",
            "resume_from_checkpoi: None\n",
            "seed                : 1000\n",
            "task                : C10-32\n",
            "verbose             : 1\n",
            "wd                  : 0\n",
            "\n",
            "\n",
            "task {'net_args': {'hid': (32, 64, 64), 'in_channels': 3, 'num_classes': 10}, 'dataset': 'CIFAR10', 'norm': ((0.49139968, 0.48215827, 0.44653124), (0.24703233, 0.24348505, 0.26158768)), 'lr': 0.003, 'target': 72.5}\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Net(\n",
            "  (fc): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "    (5): ReLU()\n",
            "    (6): AdaptiveAvgPool2d(output_size=1)\n",
            "    (7): Flatten(start_dim=1, end_dim=-1)\n",
            "    (8): Linear(in_features=64, out_features=10, bias=True)\n",
            "  )\n",
            ") params 56970 total param norm 7.6108598709106445\n",
            "base optimizer AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.003\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "/content/nino/optim/nino.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(ckpt, map_location=self.nino_device)\n",
            "\n",
            "\n",
            "kwargs {'dms_head': 'gru', 'ctx': 10, 'lpe': 8, 'seq_len': 200, 'max_feat_size': 9, 'wte_pos_enc': False, 'positional_encoding': 'learnable', 'dms_transformer_num_heads': 4, 'dms_mlp_num_layers': 2, 'dms_gru_num_layers': 2, 'dms_lstm_num_layers': 2, 'dms_transformer_num_layers': 2, 'add_edge_lpe': False}\n",
            "USING GRU HEAD\n",
            "NiNoModel(\n",
            "  (layer_embed): Embedding(15, 128)\n",
            "  (edge_proj): MLP(\n",
            "    (fc): Sequential(\n",
            "      (0): Linear(in_features=90, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (node_proj): MLP(\n",
            "    (fc): Sequential(\n",
            "      (0): Linear(in_features=8, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (gnn): PNA(\n",
            "    (act): SiLU()\n",
            "    (convs): ModuleList(\n",
            "      (0-2): 3 x PNAConv(128, 128)\n",
            "    )\n",
            "    (edge_update): ModuleList(\n",
            "      (0-1): 2 x EdgeMLP(\n",
            "        (lin_e): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (lin_s): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (lin_t): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (act): SiLU()\n",
            "        (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (edge_out): GRU_DMS(\n",
            "    (gru): GRU(128, 128, num_layers=2, batch_first=True)\n",
            "    (mlp): MLP(\n",
            "      (fc): Sequential(\n",
            "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (1): SiLU()\n",
            "        (2): Linear(in_features=128, out_features=1800, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (activation): SiLU()\n",
            "  )\n",
            ")\n",
            "NiNo with 939656 params loaded from step 5000, ckpt file ../nino_gru_head_ctx10_hor200.pt: <All keys matched successfully>\n",
            "\n",
            "k_schedule values (direct multi-step forecasting) = [200 161 126  95  69  47  29  15   6   1]\n",
            "2024-12-09 17:47:47.175881: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-09 17:47:47.193364: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-09 17:47:47.214950: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-09 17:47:47.221376: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-09 17:47:47.237065: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-09 17:47:48.560165: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Computing Laplacian positional encoding (LPE) for k=8...\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/data/storage.py:452: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'edge_index', 'pos_w', 'edge_type'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
            "  warnings.warn(\n",
            "\n",
            "Neural graph for \"Net\" (NeuralGraph) constructed in 0.011 sec:\n",
            "NeuralGraph(\n",
            "  num_nodes=177,\n",
            "  num_edges=7227,\n",
            "  edge_index=torch.Size([2, 7227]),\n",
            "  has_self_loops=True,\n",
            "  pos (LPE)=torch.Size([177, 8])\n",
            ")\n",
            "\n",
            "Training C10-32 with 359 batches per epoch for 28 epochs\n",
            "step 100, add state #1, mem on cuda:0=3.397G, cpu=1.788G\n",
            "Train 0100/10000: \tTrain loss: 1.8269 \tVal loss: 1.7810 \tVal acc: 31.76% \t(sec/b=0.023, cuda=3.397G)\n",
            "step 200, add state #2, mem on cuda:0=3.397G, cpu=1.786G\n",
            "Train 0200/10000: \tTrain loss: 1.7200 \tVal loss: 1.6796 \tVal acc: 37.36% \t(sec/b=0.020, cuda=3.397G)\n",
            "step 300, add state #3, mem on cuda:0=3.397G, cpu=1.786G\n",
            "Train 0300/10000: \tTrain loss: 1.6287 \tVal loss: 1.6228 \tVal acc: 40.80% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 400, add state #4, mem on cuda:0=3.397G, cpu=1.851G\n",
            "Train 0400/10000: \tTrain loss: 1.4527 \tVal loss: 1.5304 \tVal acc: 43.99% \t(sec/b=0.020, cuda=3.397G)\n",
            "step 500, add state #5, mem on cuda:0=3.397G, cpu=1.850G\n",
            "Train 0500/10000: \tTrain loss: 1.5017 \tVal loss: 1.5142 \tVal acc: 45.05% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 600, add state #6, mem on cuda:0=3.397G, cpu=1.850G\n",
            "Train 0600/10000: \tTrain loss: 1.2916 \tVal loss: 1.4253 \tVal acc: 48.45% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 700, add state #7, mem on cuda:0=3.397G, cpu=1.850G\n",
            "Train 0700/10000: \tTrain loss: 1.4421 \tVal loss: 1.4993 \tVal acc: 45.79% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 800, add state #8, mem on cuda:0=3.397G, cpu=1.852G\n",
            "Train 0800/10000: \tTrain loss: 1.2383 \tVal loss: 1.3438 \tVal acc: 51.05% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 900, add state #9, mem on cuda:0=3.397G, cpu=1.850G\n",
            "Train 0900/10000: \tTrain loss: 1.3614 \tVal loss: 1.3321 \tVal acc: 51.61% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1000, add state #10, mem on cuda:0=3.397G, cpu=1.850G\n",
            "loss before NiNo step: 1.3273\n",
            "\n",
            "NiNo step starting at step 1000 (k=200): peak mem on cuda:0=3.397G, cpu=1.850G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.580 sec, peak mem on cuda:0=3.397G, cpu=1.980G\n",
            "\n",
            "loss after NiNo step: 1.3060\n",
            "Train 1000/10000: \tTrain loss: 1.3060 \tVal loss: 1.3071 \tVal acc: 53.08% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1100, add state #1, mem on cuda:0=3.397G, cpu=1.982G\n",
            "Train 1100/10000: \tTrain loss: 1.3279 \tVal loss: 1.3047 \tVal acc: 52.73% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1200, add state #2, mem on cuda:0=3.397G, cpu=1.980G\n",
            "Train 1200/10000: \tTrain loss: 1.2369 \tVal loss: 1.2885 \tVal acc: 54.08% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1300, add state #3, mem on cuda:0=3.397G, cpu=1.980G\n",
            "Train 1300/10000: \tTrain loss: 1.1105 \tVal loss: 1.2617 \tVal acc: 55.13% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1400, add state #4, mem on cuda:0=3.397G, cpu=1.980G\n",
            "Train 1400/10000: \tTrain loss: 1.1576 \tVal loss: 1.2103 \tVal acc: 56.61% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1500, add state #5, mem on cuda:0=3.397G, cpu=1.982G\n",
            "Train 1500/10000: \tTrain loss: 1.1799 \tVal loss: 1.1977 \tVal acc: 57.11% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1600, add state #6, mem on cuda:0=3.397G, cpu=1.980G\n",
            "Train 1600/10000: \tTrain loss: 1.2348 \tVal loss: 1.1737 \tVal acc: 57.85% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1700, add state #7, mem on cuda:0=3.397G, cpu=1.980G\n",
            "Train 1700/10000: \tTrain loss: 0.9092 \tVal loss: 1.1726 \tVal acc: 57.69% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1800, add state #8, mem on cuda:0=3.397G, cpu=1.982G\n",
            "Train 1800/10000: \tTrain loss: 1.2687 \tVal loss: 1.1753 \tVal acc: 57.48% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1900, add state #9, mem on cuda:0=3.397G, cpu=1.980G\n",
            "Train 1900/10000: \tTrain loss: 1.0942 \tVal loss: 1.1325 \tVal acc: 59.41% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 2000, add state #10, mem on cuda:0=3.397G, cpu=1.980G\n",
            "loss before NiNo step: 1.0576\n",
            "\n",
            "NiNo step starting at step 2000 (k=161): peak mem on cuda:0=3.387G, cpu=1.980G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.022 sec, peak mem on cuda:0=3.387G, cpu=1.982G\n",
            "\n",
            "loss after NiNo step: 1.1016\n",
            "Train 2000/10000: \tTrain loss: 1.1016 \tVal loss: 1.1771 \tVal acc: 57.93% \t(sec/b=0.019, cuda=3.387G)\n",
            "step 2100, add state #1, mem on cuda:0=3.387G, cpu=1.980G\n",
            "Train 2100/10000: \tTrain loss: 0.9601 \tVal loss: 1.1221 \tVal acc: 60.21% \t(sec/b=0.019, cuda=3.387G)\n",
            "step 2200, add state #2, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 2200/10000: \tTrain loss: 1.0347 \tVal loss: 1.1221 \tVal acc: 60.30% \t(sec/b=0.019, cuda=3.387G)\n",
            "step 2300, add state #3, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 2300/10000: \tTrain loss: 1.2013 \tVal loss: 1.1157 \tVal acc: 59.73% \t(sec/b=0.019, cuda=3.387G)\n",
            "step 2400, add state #4, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 2400/10000: \tTrain loss: 1.1730 \tVal loss: 1.1211 \tVal acc: 60.46% \t(sec/b=0.019, cuda=3.387G)\n",
            "step 2500, add state #5, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 2500/10000: \tTrain loss: 0.9806 \tVal loss: 1.0555 \tVal acc: 62.37% \t(sec/b=0.019, cuda=3.387G)\n",
            "step 2600, add state #6, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 2600/10000: \tTrain loss: 1.1229 \tVal loss: 1.0292 \tVal acc: 63.81% \t(sec/b=0.019, cuda=3.387G)\n",
            "step 2700, add state #7, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 2700/10000: \tTrain loss: 1.1307 \tVal loss: 1.0686 \tVal acc: 62.29% \t(sec/b=0.019, cuda=3.387G)\n",
            "step 2800, add state #8, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 2800/10000: \tTrain loss: 0.9786 \tVal loss: 1.0180 \tVal acc: 64.37% \t(sec/b=0.019, cuda=3.387G)\n",
            "step 2900, add state #9, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 2900/10000: \tTrain loss: 1.0152 \tVal loss: 1.0317 \tVal acc: 63.97% \t(sec/b=0.019, cuda=3.387G)\n",
            "step 3000, add state #10, mem on cuda:0=3.387G, cpu=1.981G\n",
            "loss before NiNo step: 1.0307\n",
            "\n",
            "NiNo step starting at step 3000 (k=126): peak mem on cuda:0=3.387G, cpu=1.981G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.022 sec, peak mem on cuda:0=3.387G, cpu=1.982G\n",
            "\n",
            "loss after NiNo step: 1.0635\n",
            "Train 3000/10000: \tTrain loss: 1.0635 \tVal loss: 1.0190 \tVal acc: 64.46% \t(sec/b=0.019, cuda=3.387G)\n",
            "step 3100, add state #1, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 3100/10000: \tTrain loss: 1.0422 \tVal loss: 1.0236 \tVal acc: 63.91% \t(sec/b=0.019, cuda=3.387G)\n",
            "step 3200, add state #2, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 3200/10000: \tTrain loss: 0.9638 \tVal loss: 1.0079 \tVal acc: 64.40% \t(sec/b=0.019, cuda=3.387G)\n",
            "step 3300, add state #3, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 3300/10000: \tTrain loss: 1.0186 \tVal loss: 0.9991 \tVal acc: 64.73% \t(sec/b=0.019, cuda=3.387G)\n",
            "step 3400, add state #4, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 3400/10000: \tTrain loss: 1.0396 \tVal loss: 1.0103 \tVal acc: 64.44% \t(sec/b=0.019, cuda=3.387G)\n",
            "step 3500, add state #5, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 3500/10000: \tTrain loss: 0.8662 \tVal loss: 0.9931 \tVal acc: 65.34% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 3600, add state #6, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 3600/10000: \tTrain loss: 0.9135 \tVal loss: 0.9964 \tVal acc: 64.90% \t(sec/b=0.019, cuda=3.387G)\n",
            "step 3700, add state #7, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 3700/10000: \tTrain loss: 1.0012 \tVal loss: 0.9877 \tVal acc: 64.93% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 3800, add state #8, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 3800/10000: \tTrain loss: 1.0723 \tVal loss: 0.9695 \tVal acc: 66.44% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 3900, add state #9, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 3900/10000: \tTrain loss: 0.9406 \tVal loss: 0.9838 \tVal acc: 65.47% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4000, add state #10, mem on cuda:0=3.387G, cpu=1.982G\n",
            "loss before NiNo step: 0.9405\n",
            "\n",
            "NiNo step starting at step 4000 (k=95): peak mem on cuda:0=3.387G, cpu=1.982G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.022 sec, peak mem on cuda:0=3.387G, cpu=1.982G\n",
            "\n",
            "loss after NiNo step: 0.9725\n",
            "Train 4000/10000: \tTrain loss: 0.9725 \tVal loss: 0.9933 \tVal acc: 64.83% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4100, add state #1, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 4100/10000: \tTrain loss: 0.9857 \tVal loss: 0.9820 \tVal acc: 65.23% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4200, add state #2, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 4200/10000: \tTrain loss: 0.9037 \tVal loss: 0.9540 \tVal acc: 66.72% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4300, add state #3, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 4300/10000: \tTrain loss: 0.9753 \tVal loss: 0.9581 \tVal acc: 66.50% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4400, add state #4, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 4400/10000: \tTrain loss: 1.0493 \tVal loss: 0.9973 \tVal acc: 65.77% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4500, add state #5, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 4500/10000: \tTrain loss: 0.9873 \tVal loss: 0.9245 \tVal acc: 67.78% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4600, add state #6, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 4600/10000: \tTrain loss: 0.8349 \tVal loss: 0.9607 \tVal acc: 66.54% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4700, add state #7, mem on cuda:0=3.387G, cpu=1.982G\n",
            "Train 4700/10000: \tTrain loss: 0.8155 \tVal loss: 0.9761 \tVal acc: 65.53% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4800, add state #8, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 4800/10000: \tTrain loss: 0.7679 \tVal loss: 0.9323 \tVal acc: 67.30% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 4900, add state #9, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 4900/10000: \tTrain loss: 1.0323 \tVal loss: 0.9110 \tVal acc: 68.10% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 5000, add state #10, mem on cuda:0=3.387G, cpu=1.981G\n",
            "loss before NiNo step: 0.9458\n",
            "\n",
            "NiNo step starting at step 5000 (k=69): peak mem on cuda:0=3.385G, cpu=1.981G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.025 sec, peak mem on cuda:0=3.385G, cpu=1.983G\n",
            "\n",
            "loss after NiNo step: 0.9899\n",
            "Train 5000/10000: \tTrain loss: 0.9899 \tVal loss: 0.9473 \tVal acc: 67.31% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5100, add state #1, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 5100/10000: \tTrain loss: 0.8351 \tVal loss: 0.9120 \tVal acc: 67.55% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5200, add state #2, mem on cuda:0=3.385G, cpu=1.981G\n",
            "Train 5200/10000: \tTrain loss: 0.8837 \tVal loss: 0.9316 \tVal acc: 67.47% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5300, add state #3, mem on cuda:0=3.385G, cpu=1.981G\n",
            "Train 5300/10000: \tTrain loss: 0.7455 \tVal loss: 0.9042 \tVal acc: 68.93% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5400, add state #4, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 5400/10000: \tTrain loss: 0.8833 \tVal loss: 0.9246 \tVal acc: 67.76% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5500, add state #5, mem on cuda:0=3.385G, cpu=1.981G\n",
            "Train 5500/10000: \tTrain loss: 0.8205 \tVal loss: 0.8906 \tVal acc: 69.14% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5600, add state #6, mem on cuda:0=3.385G, cpu=1.981G\n",
            "Train 5600/10000: \tTrain loss: 0.7906 \tVal loss: 0.9143 \tVal acc: 68.69% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5700, add state #7, mem on cuda:0=3.385G, cpu=1.981G\n",
            "Train 5700/10000: \tTrain loss: 0.8513 \tVal loss: 0.8789 \tVal acc: 69.59% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5800, add state #8, mem on cuda:0=3.387G, cpu=1.983G\n",
            "Train 5800/10000: \tTrain loss: 0.7917 \tVal loss: 0.8612 \tVal acc: 70.07% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 5900, add state #9, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 5900/10000: \tTrain loss: 0.8154 \tVal loss: 0.9150 \tVal acc: 67.61% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 6000, add state #10, mem on cuda:0=3.387G, cpu=1.981G\n",
            "loss before NiNo step: 0.7624\n",
            "\n",
            "NiNo step starting at step 6000 (k=47): peak mem on cuda:0=3.387G, cpu=1.981G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.024 sec, peak mem on cuda:0=3.387G, cpu=1.983G\n",
            "\n",
            "loss after NiNo step: 0.7682\n",
            "Train 6000/10000: \tTrain loss: 0.7682 \tVal loss: 0.8712 \tVal acc: 69.76% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 6100, add state #1, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 6100/10000: \tTrain loss: 0.8023 \tVal loss: 0.8663 \tVal acc: 70.31% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 6200, add state #2, mem on cuda:0=3.387G, cpu=1.983G\n",
            "Train 6200/10000: \tTrain loss: 0.7098 \tVal loss: 0.9618 \tVal acc: 66.24% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 6300, add state #3, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 6300/10000: \tTrain loss: 0.7965 \tVal loss: 0.8683 \tVal acc: 70.18% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 6400, add state #4, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 6400/10000: \tTrain loss: 0.8176 \tVal loss: 0.9153 \tVal acc: 68.21% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 6500, add state #5, mem on cuda:0=3.387G, cpu=1.983G\n",
            "Train 6500/10000: \tTrain loss: 0.8474 \tVal loss: 0.9130 \tVal acc: 69.12% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 6600, add state #6, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 6600/10000: \tTrain loss: 0.8438 \tVal loss: 0.8883 \tVal acc: 69.18% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 6700, add state #7, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 6700/10000: \tTrain loss: 0.7958 \tVal loss: 0.8665 \tVal acc: 70.39% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 6800, add state #8, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 6800/10000: \tTrain loss: 0.7597 \tVal loss: 0.8522 \tVal acc: 71.00% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 6900, add state #9, mem on cuda:0=3.387G, cpu=1.983G\n",
            "Train 6900/10000: \tTrain loss: 0.7020 \tVal loss: 0.8473 \tVal acc: 71.25% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 7000, add state #10, mem on cuda:0=3.387G, cpu=1.981G\n",
            "loss before NiNo step: 0.8086\n",
            "\n",
            "NiNo step starting at step 7000 (k=29): peak mem on cuda:0=3.387G, cpu=1.981G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.022 sec, peak mem on cuda:0=3.387G, cpu=1.983G\n",
            "\n",
            "loss after NiNo step: 2.0687\n",
            "Train 7000/10000: \tTrain loss: 2.0687 \tVal loss: 2.0023 \tVal acc: 31.76% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 7100, add state #1, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 7100/10000: \tTrain loss: 0.7157 \tVal loss: 0.8754 \tVal acc: 69.69% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 7200, add state #2, mem on cuda:0=3.387G, cpu=1.983G\n",
            "Train 7200/10000: \tTrain loss: 0.7840 \tVal loss: 0.8586 \tVal acc: 70.04% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 7300, add state #3, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 7300/10000: \tTrain loss: 0.7555 \tVal loss: 0.8582 \tVal acc: 70.44% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 7400, add state #4, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 7400/10000: \tTrain loss: 0.7785 \tVal loss: 0.8557 \tVal acc: 70.69% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 7500, add state #5, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 7500/10000: \tTrain loss: 0.6923 \tVal loss: 0.8890 \tVal acc: 69.15% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 7600, add state #6, mem on cuda:0=3.387G, cpu=1.983G\n",
            "Train 7600/10000: \tTrain loss: 0.7600 \tVal loss: 0.8429 \tVal acc: 70.47% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 7700, add state #7, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 7700/10000: \tTrain loss: 0.8414 \tVal loss: 0.8492 \tVal acc: 71.13% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 7800, add state #8, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 7800/10000: \tTrain loss: 0.7980 \tVal loss: 0.8422 \tVal acc: 70.90% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 7900, add state #9, mem on cuda:0=3.387G, cpu=1.983G\n",
            "Train 7900/10000: \tTrain loss: 0.7417 \tVal loss: 0.8494 \tVal acc: 71.13% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 8000, add state #10, mem on cuda:0=3.387G, cpu=1.981G\n",
            "loss before NiNo step: 0.7132\n",
            "\n",
            "NiNo step starting at step 8000 (k=15): peak mem on cuda:0=3.387G, cpu=1.981G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.024 sec, peak mem on cuda:0=3.387G, cpu=1.983G\n",
            "\n",
            "loss after NiNo step: 1.1165\n",
            "Train 8000/10000: \tTrain loss: 1.1165 \tVal loss: 1.2406 \tVal acc: 57.51% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 8100, add state #1, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 8100/10000: \tTrain loss: 0.8051 \tVal loss: 0.8553 \tVal acc: 70.34% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 8200, add state #2, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 8200/10000: \tTrain loss: 0.8170 \tVal loss: 0.8614 \tVal acc: 70.39% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 8300, add state #3, mem on cuda:0=3.387G, cpu=1.983G\n",
            "Train 8300/10000: \tTrain loss: 0.8683 \tVal loss: 0.8398 \tVal acc: 70.94% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 8400, add state #4, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 8400/10000: \tTrain loss: 0.8349 \tVal loss: 0.8624 \tVal acc: 70.48% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 8500, add state #5, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 8500/10000: \tTrain loss: 0.6264 \tVal loss: 0.8493 \tVal acc: 70.98% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 8600, add state #6, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 8600/10000: \tTrain loss: 0.7725 \tVal loss: 0.8265 \tVal acc: 71.68% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 8700, add state #7, mem on cuda:0=3.387G, cpu=1.983G\n",
            "Train 8700/10000: \tTrain loss: 0.6520 \tVal loss: 0.8444 \tVal acc: 70.87% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 8800, add state #8, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 8800/10000: \tTrain loss: 0.7225 \tVal loss: 0.8709 \tVal acc: 70.23% \t(sec/b=0.018, cuda=3.387G)\n",
            "step 8900, add state #9, mem on cuda:0=3.387G, cpu=1.981G\n",
            "Train 8900/10000: \tTrain loss: 0.7133 \tVal loss: 0.8359 \tVal acc: 71.79% \t(sec/b=0.018, cuda=3.387G)\n",
            "\n",
            "Reached target accuracy of 72.53%>=72.50% in 8970 steps (163.5401 seconds)\n",
            "esults/step_8970.pt at epoch=24, step=353, completed_steps=8970\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train_vision.py --task C10-32 --head \"mlp\" --nino_ckpt_mlp \"../nino_mlp_head_ctx10_hor100.pt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxUmxiOfjYgk",
        "outputId": "612edb70-f8ce-4b0c-e6be-face41120f87"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Environment:\n",
            "git commit          : 1ae2c09\n",
            "hostname            : 10d1e8aed3f2\n",
            "torch               : 2.5.1+cu121\n",
            "torchvision         : 0.20.1+cu121\n",
            "transformers        : 4.46.3\n",
            "cuda available      : True\n",
            "cudnn enabled       : True\n",
            "cuda version        : 12.1\n",
            "start time          : 20241209-175338\n",
            "\n",
            "Script Arguments:\n",
            "batch_size          : 128\n",
            "checkpointing_steps : None\n",
            "device              : cuda\n",
            "env                 : {'git commit': '1ae2c09', 'hostname': '10d1e8aed3f2', 'torch': '2.5.1+cu121', 'torchvision': '0.20.1+cu121', 'transformers': '4.46.3', 'cuda available': True, 'cudnn enabled': True, 'cuda version': '12.1', 'start time': '20241209-175338'}\n",
            "head                : mlp\n",
            "log_interval        : 100\n",
            "lr                  : None\n",
            "max_train_steps     : 10000\n",
            "nino_ckpt_gru       : ../nino_gru_head_ctx10_hor40.pt\n",
            "nino_ckpt_hybrid    : ../nino_hybrid_head_ctx10_hor40.pt\n",
            "nino_ckpt_lstm      : ../nino_lstm_ctx10_head_ctx10_hor40.pt\n",
            "nino_ckpt_mlp       : ../nino_mlp_head_ctx10_hor100.pt\n",
            "num_workers         : 4\n",
            "output_dir          : ..\results\n",
            "period              : 1000\n",
            "resume_from_checkpoi: None\n",
            "seed                : 1000\n",
            "task                : C10-32\n",
            "verbose             : 1\n",
            "wd                  : 0\n",
            "\n",
            "\n",
            "task {'net_args': {'hid': (32, 64, 64), 'in_channels': 3, 'num_classes': 10}, 'dataset': 'CIFAR10', 'norm': ((0.49139968, 0.48215827, 0.44653124), (0.24703233, 0.24348505, 0.26158768)), 'lr': 0.003, 'target': 72.5}\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Net(\n",
            "  (fc): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "    (5): ReLU()\n",
            "    (6): AdaptiveAvgPool2d(output_size=1)\n",
            "    (7): Flatten(start_dim=1, end_dim=-1)\n",
            "    (8): Linear(in_features=64, out_features=10, bias=True)\n",
            "  )\n",
            ") params 56970 total param norm 7.6108598709106445\n",
            "base optimizer AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.003\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "/content/nino/optim/nino.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(ckpt, map_location=self.nino_device)\n",
            "\n",
            "\n",
            "kwargs {'dms_head': 'lstm', 'ctx': 10, 'lpe': 8, 'seq_len': 100, 'max_feat_size': 9, 'wte_pos_enc': False, 'positional_encoding': 'learnable', 'dms_transformer_num_heads': 4, 'dms_mlp_num_layers': 2, 'dms_gru_num_layers': 2, 'dms_lstm_num_layers': 2, 'dms_transformer_num_layers': 2, 'add_edge_lpe': False}\n",
            "USING LSTM HEAD\n",
            "NiNoModel(\n",
            "  (layer_embed): Embedding(15, 128)\n",
            "  (edge_proj): MLP(\n",
            "    (fc): Sequential(\n",
            "      (0): Linear(in_features=90, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (node_proj): MLP(\n",
            "    (fc): Sequential(\n",
            "      (0): Linear(in_features=8, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (gnn): PNA(\n",
            "    (act): SiLU()\n",
            "    (convs): ModuleList(\n",
            "      (0-2): 3 x PNAConv(128, 128)\n",
            "    )\n",
            "    (edge_update): ModuleList(\n",
            "      (0-1): 2 x EdgeMLP(\n",
            "        (lin_e): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (lin_s): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (lin_t): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (act): SiLU()\n",
            "        (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (edge_out): LSTM_DMS(\n",
            "    (lstm): LSTM(128, 128, num_layers=2, batch_first=True)\n",
            "    (mlp): MLP(\n",
            "      (fc): Sequential(\n",
            "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "        (1): SiLU()\n",
            "        (2): Linear(in_features=128, out_features=900, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (activation): SiLU()\n",
            "  )\n",
            ")\n",
            "NiNo with 889604 params loaded from step 5000, ckpt file ../nino_mlp_head_ctx10_hor100.pt: <All keys matched successfully>\n",
            "\n",
            "k_schedule values (direct multi-step forecasting) = [100  81  64  49  36  25  16   9   4   1]\n",
            "2024-12-09 17:53:43.449677: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-09 17:53:43.468026: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-09 17:53:43.489717: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-09 17:53:43.496213: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-09 17:53:43.512216: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-09 17:53:44.820136: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Computing Laplacian positional encoding (LPE) for k=8...\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/data/storage.py:452: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'edge_index', 'pos_w', 'edge_type'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
            "  warnings.warn(\n",
            "\n",
            "Neural graph for \"Net\" (NeuralGraph) constructed in 0.011 sec:\n",
            "NeuralGraph(\n",
            "  num_nodes=177,\n",
            "  num_edges=7227,\n",
            "  edge_index=torch.Size([2, 7227]),\n",
            "  has_self_loops=True,\n",
            "  pos (LPE)=torch.Size([177, 8])\n",
            ")\n",
            "\n",
            "Training C10-32 with 359 batches per epoch for 28 epochs\n",
            "step 100, add state #1, mem on cuda:0=3.393G, cpu=1.790G\n",
            "Train 0100/10000: \tTrain loss: 1.8269 \tVal loss: 1.7810 \tVal acc: 31.76% \t(sec/b=0.023, cuda=3.393G)\n",
            "step 200, add state #2, mem on cuda:0=3.393G, cpu=1.788G\n",
            "Train 0200/10000: \tTrain loss: 1.7200 \tVal loss: 1.6796 \tVal acc: 37.36% \t(sec/b=0.020, cuda=3.393G)\n",
            "step 300, add state #3, mem on cuda:0=3.393G, cpu=1.788G\n",
            "Train 0300/10000: \tTrain loss: 1.6287 \tVal loss: 1.6228 \tVal acc: 40.80% \t(sec/b=0.019, cuda=3.393G)\n",
            "step 400, add state #4, mem on cuda:0=3.395G, cpu=1.853G\n",
            "Train 0400/10000: \tTrain loss: 1.4527 \tVal loss: 1.5304 \tVal acc: 43.99% \t(sec/b=0.019, cuda=3.395G)\n",
            "step 500, add state #5, mem on cuda:0=3.395G, cpu=1.852G\n",
            "Train 0500/10000: \tTrain loss: 1.5020 \tVal loss: 1.5143 \tVal acc: 45.02% \t(sec/b=0.019, cuda=3.395G)\n",
            "step 600, add state #6, mem on cuda:0=3.395G, cpu=1.852G\n",
            "Train 0600/10000: \tTrain loss: 1.2919 \tVal loss: 1.4248 \tVal acc: 48.45% \t(sec/b=0.019, cuda=3.395G)\n",
            "step 700, add state #7, mem on cuda:0=3.395G, cpu=1.852G\n",
            "Train 0700/10000: \tTrain loss: 1.4464 \tVal loss: 1.4997 \tVal acc: 45.59% \t(sec/b=0.018, cuda=3.395G)\n",
            "step 800, add state #8, mem on cuda:0=3.397G, cpu=1.853G\n",
            "Train 0800/10000: \tTrain loss: 1.2446 \tVal loss: 1.3477 \tVal acc: 50.90% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 900, add state #9, mem on cuda:0=3.397G, cpu=1.852G\n",
            "Train 0900/10000: \tTrain loss: 1.3634 \tVal loss: 1.3293 \tVal acc: 51.62% \t(sec/b=0.018, cuda=3.397G)\n",
            "step 1000, add state #10, mem on cuda:0=3.397G, cpu=1.852G\n",
            "loss before NiNo step: 1.3240\n",
            "\n",
            "NiNo step starting at step 1000 (k=100): peak mem on cuda:0=3.397G, cpu=1.852G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.548 sec, peak mem on cuda:0=3.397G, cpu=1.981G\n",
            "\n",
            "loss after NiNo step: 4.7048\n",
            "Train 1000/10000: \tTrain loss: 4.7048 \tVal loss: 4.6744 \tVal acc: 21.50% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1100, add state #1, mem on cuda:0=3.397G, cpu=1.982G\n",
            "Train 1100/10000: \tTrain loss: 1.3909 \tVal loss: 1.3321 \tVal acc: 52.14% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1200, add state #2, mem on cuda:0=3.397G, cpu=1.981G\n",
            "Train 1200/10000: \tTrain loss: 1.2211 \tVal loss: 1.2840 \tVal acc: 54.63% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1300, add state #3, mem on cuda:0=3.397G, cpu=1.981G\n",
            "Train 1300/10000: \tTrain loss: 1.1355 \tVal loss: 1.2594 \tVal acc: 54.97% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1400, add state #4, mem on cuda:0=3.397G, cpu=1.981G\n",
            "Train 1400/10000: \tTrain loss: 1.1922 \tVal loss: 1.2242 \tVal acc: 56.15% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1500, add state #5, mem on cuda:0=3.397G, cpu=1.983G\n",
            "Train 1500/10000: \tTrain loss: 1.1942 \tVal loss: 1.2224 \tVal acc: 55.95% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1600, add state #6, mem on cuda:0=3.397G, cpu=1.981G\n",
            "Train 1600/10000: \tTrain loss: 1.2445 \tVal loss: 1.1922 \tVal acc: 56.80% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1700, add state #7, mem on cuda:0=3.397G, cpu=1.981G\n",
            "Train 1700/10000: \tTrain loss: 0.8979 \tVal loss: 1.1792 \tVal acc: 57.52% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1800, add state #8, mem on cuda:0=3.397G, cpu=1.983G\n",
            "Train 1800/10000: \tTrain loss: 1.3022 \tVal loss: 1.1885 \tVal acc: 57.08% \t(sec/b=0.019, cuda=3.397G)\n",
            "step 1900, add state #9, mem on cuda:0=3.397G, cpu=1.981G\n",
            "Train 1900/10000: \tTrain loss: 1.1046 \tVal loss: 1.1420 \tVal acc: 59.04% \t(sec/b=0.018, cuda=3.397G)\n",
            "step 2000, add state #10, mem on cuda:0=3.397G, cpu=1.981G\n",
            "loss before NiNo step: 1.0644\n",
            "\n",
            "NiNo step starting at step 2000 (k=81): peak mem on cuda:0=3.385G, cpu=1.981G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.028 sec, peak mem on cuda:0=3.385G, cpu=1.983G\n",
            "\n",
            "loss after NiNo step: 1.1165\n",
            "Train 2000/10000: \tTrain loss: 1.1165 \tVal loss: 1.2432 \tVal acc: 55.22% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 2100, add state #1, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 2100/10000: \tTrain loss: 0.9736 \tVal loss: 1.1282 \tVal acc: 59.75% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 2200, add state #2, mem on cuda:0=3.385G, cpu=1.984G\n",
            "Train 2200/10000: \tTrain loss: 1.0254 \tVal loss: 1.1352 \tVal acc: 60.19% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 2300, add state #3, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 2300/10000: \tTrain loss: 1.2346 \tVal loss: 1.1240 \tVal acc: 59.58% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 2400, add state #4, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 2400/10000: \tTrain loss: 1.2029 \tVal loss: 1.1471 \tVal acc: 59.56% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 2500, add state #5, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 2500/10000: \tTrain loss: 0.9923 \tVal loss: 1.0480 \tVal acc: 62.75% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 2600, add state #6, mem on cuda:0=3.385G, cpu=1.984G\n",
            "Train 2600/10000: \tTrain loss: 1.1149 \tVal loss: 1.0334 \tVal acc: 64.27% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 2700, add state #7, mem on cuda:0=3.385G, cpu=1.982G\n",
            "Train 2700/10000: \tTrain loss: 1.1186 \tVal loss: 1.0536 \tVal acc: 62.53% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 2800, add state #8, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 2800/10000: \tTrain loss: 0.9928 \tVal loss: 1.0236 \tVal acc: 64.39% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 2900, add state #9, mem on cuda:0=3.385G, cpu=1.984G\n",
            "Train 2900/10000: \tTrain loss: 1.0142 \tVal loss: 1.0228 \tVal acc: 64.10% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 3000, add state #10, mem on cuda:0=3.385G, cpu=1.983G\n",
            "loss before NiNo step: 1.0349\n",
            "\n",
            "NiNo step starting at step 3000 (k=64): peak mem on cuda:0=3.385G, cpu=1.983G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.023 sec, peak mem on cuda:0=3.385G, cpu=1.984G\n",
            "\n",
            "loss after NiNo step: 1.0411\n",
            "Train 3000/10000: \tTrain loss: 1.0411 \tVal loss: 1.0348 \tVal acc: 63.49% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 3100, add state #1, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 3100/10000: \tTrain loss: 1.0861 \tVal loss: 1.0199 \tVal acc: 64.27% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 3200, add state #2, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 3200/10000: \tTrain loss: 0.9592 \tVal loss: 1.0034 \tVal acc: 64.42% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 3300, add state #3, mem on cuda:0=3.385G, cpu=1.984G\n",
            "Train 3300/10000: \tTrain loss: 1.0117 \tVal loss: 0.9849 \tVal acc: 65.44% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 3400, add state #4, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 3400/10000: \tTrain loss: 1.0516 \tVal loss: 1.0265 \tVal acc: 64.08% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 3500, add state #5, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 3500/10000: \tTrain loss: 0.8664 \tVal loss: 0.9742 \tVal acc: 65.83% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 3600, add state #6, mem on cuda:0=3.385G, cpu=1.984G\n",
            "Train 3600/10000: \tTrain loss: 0.9064 \tVal loss: 0.9959 \tVal acc: 65.02% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 3700, add state #7, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 3700/10000: \tTrain loss: 0.9592 \tVal loss: 0.9900 \tVal acc: 64.76% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 3800, add state #8, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 3800/10000: \tTrain loss: 1.0858 \tVal loss: 0.9483 \tVal acc: 67.20% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 3900, add state #9, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 3900/10000: \tTrain loss: 0.9183 \tVal loss: 0.9529 \tVal acc: 66.53% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 4000, add state #10, mem on cuda:0=3.385G, cpu=1.984G\n",
            "loss before NiNo step: 0.9387\n",
            "\n",
            "NiNo step starting at step 4000 (k=49): peak mem on cuda:0=3.385G, cpu=1.984G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.023 sec, peak mem on cuda:0=3.385G, cpu=1.984G\n",
            "\n",
            "loss after NiNo step: 1.0380\n",
            "Train 4000/10000: \tTrain loss: 1.0380 \tVal loss: 1.1893 \tVal acc: 59.95% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 4100, add state #1, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 4100/10000: \tTrain loss: 0.9865 \tVal loss: 0.9570 \tVal acc: 66.43% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 4200, add state #2, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 4200/10000: \tTrain loss: 0.8581 \tVal loss: 0.9272 \tVal acc: 67.31% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 4300, add state #3, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 4300/10000: \tTrain loss: 0.9442 \tVal loss: 0.9375 \tVal acc: 66.98% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 4400, add state #4, mem on cuda:0=3.385G, cpu=1.984G\n",
            "Train 4400/10000: \tTrain loss: 1.0231 \tVal loss: 0.9655 \tVal acc: 66.97% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 4500, add state #5, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 4500/10000: \tTrain loss: 0.9524 \tVal loss: 0.9075 \tVal acc: 68.60% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 4600, add state #6, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 4600/10000: \tTrain loss: 0.8133 \tVal loss: 0.9102 \tVal acc: 68.25% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 4700, add state #7, mem on cuda:0=3.385G, cpu=1.984G\n",
            "Train 4700/10000: \tTrain loss: 0.8077 \tVal loss: 0.9534 \tVal acc: 66.47% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 4800, add state #8, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 4800/10000: \tTrain loss: 0.8049 \tVal loss: 0.8999 \tVal acc: 68.48% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 4900, add state #9, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 4900/10000: \tTrain loss: 1.0143 \tVal loss: 0.8873 \tVal acc: 69.38% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5000, add state #10, mem on cuda:0=3.385G, cpu=1.983G\n",
            "loss before NiNo step: 0.9139\n",
            "\n",
            "NiNo step starting at step 5000 (k=36): peak mem on cuda:0=3.385G, cpu=1.983G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.023 sec, peak mem on cuda:0=3.385G, cpu=1.984G\n",
            "\n",
            "loss after NiNo step: 228.9084\n",
            "Train 5000/10000: \tTrain loss: 228.9084 \tVal loss: 193.3008 \tVal acc: 10.51% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5100, add state #1, mem on cuda:0=3.385G, cpu=1.984G\n",
            "Train 5100/10000: \tTrain loss: 2.2984 \tVal loss: 2.3054 \tVal acc: 13.49% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5200, add state #2, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 5200/10000: \tTrain loss: 2.2483 \tVal loss: 2.2171 \tVal acc: 18.08% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5300, add state #3, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 5300/10000: \tTrain loss: 2.1408 \tVal loss: 2.1281 \tVal acc: 21.79% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5400, add state #4, mem on cuda:0=3.385G, cpu=1.984G\n",
            "Train 5400/10000: \tTrain loss: 2.0140 \tVal loss: 2.0434 \tVal acc: 25.65% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5500, add state #5, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 5500/10000: \tTrain loss: 2.0476 \tVal loss: 1.9726 \tVal acc: 28.71% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5600, add state #6, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 5600/10000: \tTrain loss: 1.9024 \tVal loss: 1.8846 \tVal acc: 31.50% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5700, add state #7, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 5700/10000: \tTrain loss: 1.8205 \tVal loss: 1.8239 \tVal acc: 32.63% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5800, add state #8, mem on cuda:0=3.385G, cpu=1.984G\n",
            "Train 5800/10000: \tTrain loss: 1.7195 \tVal loss: 1.7743 \tVal acc: 35.09% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 5900, add state #9, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 5900/10000: \tTrain loss: 1.7010 \tVal loss: 1.7263 \tVal acc: 36.20% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6000, add state #10, mem on cuda:0=3.385G, cpu=1.983G\n",
            "loss before NiNo step: 1.5925\n",
            "\n",
            "NiNo step starting at step 6000 (k=25): peak mem on cuda:0=3.385G, cpu=1.983G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.022 sec, peak mem on cuda:0=3.385G, cpu=1.984G\n",
            "\n",
            "loss after NiNo step: 86.1962\n",
            "Train 6000/10000: \tTrain loss: 86.1962 \tVal loss: 100.0280 \tVal acc: 12.80% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6100, add state #1, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 6100/10000: \tTrain loss: 2.0341 \tVal loss: 2.0487 \tVal acc: 23.45% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6200, add state #2, mem on cuda:0=3.385G, cpu=1.985G\n",
            "Train 6200/10000: \tTrain loss: 1.7892 \tVal loss: 1.9328 \tVal acc: 27.92% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6300, add state #3, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 6300/10000: \tTrain loss: 1.8744 \tVal loss: 1.8756 \tVal acc: 29.24% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6400, add state #4, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 6400/10000: \tTrain loss: 1.7497 \tVal loss: 1.8313 \tVal acc: 30.79% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6500, add state #5, mem on cuda:0=3.385G, cpu=1.985G\n",
            "Train 6500/10000: \tTrain loss: 1.7169 \tVal loss: 1.8084 \tVal acc: 32.44% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6600, add state #6, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 6600/10000: \tTrain loss: 1.9098 \tVal loss: 1.7698 \tVal acc: 33.26% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6700, add state #7, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 6700/10000: \tTrain loss: 1.7772 \tVal loss: 1.7386 \tVal acc: 33.91% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6800, add state #8, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 6800/10000: \tTrain loss: 1.5126 \tVal loss: 1.6964 \tVal acc: 35.92% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 6900, add state #9, mem on cuda:0=3.385G, cpu=1.985G\n",
            "Train 6900/10000: \tTrain loss: 1.6731 \tVal loss: 1.6607 \tVal acc: 38.29% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7000, add state #10, mem on cuda:0=3.385G, cpu=1.983G\n",
            "loss before NiNo step: 1.6567\n",
            "\n",
            "NiNo step starting at step 7000 (k=16): peak mem on cuda:0=3.385G, cpu=1.983G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.022 sec, peak mem on cuda:0=3.385G, cpu=1.985G\n",
            "\n",
            "loss after NiNo step: 258.0303\n",
            "Train 7000/10000: \tTrain loss: 258.0303 \tVal loss: 243.2681 \tVal acc: 12.19% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7100, add state #1, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 7100/10000: \tTrain loss: 2.3410 \tVal loss: 2.2450 \tVal acc: 20.71% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7200, add state #2, mem on cuda:0=3.385G, cpu=1.985G\n",
            "Train 7200/10000: \tTrain loss: 2.0515 \tVal loss: 2.0819 \tVal acc: 24.39% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7300, add state #3, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 7300/10000: \tTrain loss: 2.0830 \tVal loss: 2.0003 \tVal acc: 27.10% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7400, add state #4, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 7400/10000: \tTrain loss: 2.0293 \tVal loss: 1.9164 \tVal acc: 29.43% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7500, add state #5, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 7500/10000: \tTrain loss: 1.7590 \tVal loss: 1.8704 \tVal acc: 30.53% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7600, add state #6, mem on cuda:0=3.385G, cpu=1.985G\n",
            "Train 7600/10000: \tTrain loss: 1.8647 \tVal loss: 1.8326 \tVal acc: 32.62% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7700, add state #7, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 7700/10000: \tTrain loss: 1.9303 \tVal loss: 1.8208 \tVal acc: 32.73% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7800, add state #8, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 7800/10000: \tTrain loss: 1.8477 \tVal loss: 1.7876 \tVal acc: 34.56% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 7900, add state #9, mem on cuda:0=3.385G, cpu=1.985G\n",
            "Train 7900/10000: \tTrain loss: 1.8934 \tVal loss: 1.7713 \tVal acc: 34.73% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 8000, add state #10, mem on cuda:0=3.385G, cpu=1.983G\n",
            "loss before NiNo step: 1.7272\n",
            "\n",
            "NiNo step starting at step 8000 (k=9): peak mem on cuda:0=3.385G, cpu=1.983G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.023 sec, peak mem on cuda:0=3.385G, cpu=1.985G\n",
            "\n",
            "loss after NiNo step: 52.5670\n",
            "Train 8000/10000: \tTrain loss: 52.5670 \tVal loss: 58.1740 \tVal acc: 10.83% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 8100, add state #1, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 8100/10000: \tTrain loss: 2.0557 \tVal loss: 2.1228 \tVal acc: 27.03% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 8200, add state #2, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 8200/10000: \tTrain loss: 1.9639 \tVal loss: 1.9682 \tVal acc: 30.02% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 8300, add state #3, mem on cuda:0=3.385G, cpu=1.985G\n",
            "Train 8300/10000: \tTrain loss: 1.9220 \tVal loss: 1.9001 \tVal acc: 31.57% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 8400, add state #4, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 8400/10000: \tTrain loss: 1.9460 \tVal loss: 1.8725 \tVal acc: 31.80% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 8500, add state #5, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 8500/10000: \tTrain loss: 1.5981 \tVal loss: 1.8358 \tVal acc: 33.14% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 8600, add state #6, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 8600/10000: \tTrain loss: 1.7929 \tVal loss: 1.8091 \tVal acc: 33.24% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 8700, add state #7, mem on cuda:0=3.385G, cpu=1.985G\n",
            "Train 8700/10000: \tTrain loss: 1.8941 \tVal loss: 1.7934 \tVal acc: 34.44% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 8800, add state #8, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 8800/10000: \tTrain loss: 1.8250 \tVal loss: 1.7659 \tVal acc: 35.54% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 8900, add state #9, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 8900/10000: \tTrain loss: 1.7684 \tVal loss: 1.7599 \tVal acc: 35.18% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 9000, add state #10, mem on cuda:0=3.385G, cpu=1.985G\n",
            "loss before NiNo step: 1.7771\n",
            "\n",
            "NiNo step starting at step 9000 (k=4): peak mem on cuda:0=3.385G, cpu=1.985G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.022 sec, peak mem on cuda:0=3.385G, cpu=1.985G\n",
            "\n",
            "loss after NiNo step: 35.6406\n",
            "Train 9000/10000: \tTrain loss: 35.6406 \tVal loss: 40.9636 \tVal acc: 11.29% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 9100, add state #1, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 9100/10000: \tTrain loss: 1.9276 \tVal loss: 1.9966 \tVal acc: 30.05% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 9200, add state #2, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 9200/10000: \tTrain loss: 1.8318 \tVal loss: 1.8825 \tVal acc: 33.30% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 9300, add state #3, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 9300/10000: \tTrain loss: 1.8737 \tVal loss: 1.8232 \tVal acc: 34.61% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 9400, add state #4, mem on cuda:0=3.385G, cpu=1.985G\n",
            "Train 9400/10000: \tTrain loss: 1.7700 \tVal loss: 1.8101 \tVal acc: 35.08% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 9500, add state #5, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 9500/10000: \tTrain loss: 1.7618 \tVal loss: 1.7707 \tVal acc: 35.08% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 9600, add state #6, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 9600/10000: \tTrain loss: 1.7969 \tVal loss: 1.7542 \tVal acc: 35.98% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 9700, add state #7, mem on cuda:0=3.385G, cpu=1.985G\n",
            "Train 9700/10000: \tTrain loss: 1.7866 \tVal loss: 1.7927 \tVal acc: 35.21% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 9800, add state #8, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 9800/10000: \tTrain loss: 1.7122 \tVal loss: 1.7299 \tVal acc: 36.74% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 9900, add state #9, mem on cuda:0=3.385G, cpu=1.983G\n",
            "Train 9900/10000: \tTrain loss: 1.7537 \tVal loss: 1.7219 \tVal acc: 37.01% \t(sec/b=0.018, cuda=3.385G)\n",
            "step 10000, add state #10, mem on cuda:0=3.385G, cpu=1.983G\n",
            "loss before NiNo step: 1.7647\n",
            "\n",
            "NiNo step starting at step 10000 (k=1): peak mem on cuda:0=3.385G, cpu=1.983G\n",
            "creating edge_attr with shape (7227, 90) cuda:0\n",
            "running the meta model\n",
            "NiNo step finished: 0.023 sec, peak mem on cuda:0=3.385G, cpu=1.985G\n",
            "\n",
            "loss after NiNo step: 59.4694\n",
            "Train 10000/10000: \tTrain loss: 59.4694 \tVal loss: 59.2500 \tVal acc: 10.11% \t(sec/b=0.018, cuda=3.385G)\n",
            "esults/step_10000.pt at epoch=27, step=306, completed_steps=10000\n",
            "Done!\n"
          ]
        }
      ]
    }
  ]
}